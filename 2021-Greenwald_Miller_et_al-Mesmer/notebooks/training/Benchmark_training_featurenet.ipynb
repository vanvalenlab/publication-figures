{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook trains a featurenet model on the TissueNet dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# create folder for this set of experiments\n",
    "experiment_folder = \"featurenet\"\n",
    "MODEL_DIR = os.path.join(\"/data/analyses\", experiment_folder)\n",
    "NPZ_DIR = \"/data/npz_data/20201018_freeze/\"\n",
    "LOG_DIR = '/data/logs'\n",
    "\n",
    "if not os.path.isdir(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up filepath constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "from deepcell.utils.train_utils import rate_scheduler\n",
    "\n",
    "model = '3'\n",
    "\n",
    "conv_model_name = 'featurenet_split_{}_100_epochs'.format(model)\n",
    "npz_name = \"20201018_multiplex_seed_{}_train_256x256.npz\".format(model)\n",
    "DATA_FILE = os.path.join(NPZ_DIR, npz_name)\n",
    "\n",
    "n_epoch = 25  # Number of training epochs\n",
    "norm_method = None  # data normalization\n",
    "receptive_field = 61  # should be adjusted for the scale of the data\n",
    "\n",
    "optimizer = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "lr_sched = rate_scheduler(lr=0.01, decay=0.99)\n",
    "\n",
    "# FC training settings\n",
    "n_skips = 3  # number of skip-connections (only for FC training)\n",
    "batch_size = 1  # FC training uses 1 image per batch\n",
    "\n",
    "# Transformation settings\n",
    "transform = 'pixelwise'\n",
    "dilation_radius = 1  # change dilation radius for edge dilation\n",
    "separate_edge_classes = False  # break edges into cell-background edge, cell-cell edge\n",
    "n_features = 4 if separate_edge_classes else 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, Create a model for the edge/interior segmentation\n",
    "\n",
    "#### Instantiate the segmentation transform model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1115 03:11:12.391070 140369887557440 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "from deepcell import model_zoo\n",
    "\n",
    "conv_model = model_zoo.bn_feature_net_skip_2D(\n",
    "    receptive_field=receptive_field,\n",
    "    n_skips=n_skips,\n",
    "    n_features=n_features,\n",
    "    norm_method=norm_method,\n",
    "    n_conv_filters=32,\n",
    "    n_dense_filters=128,\n",
    "    last_only=False,\n",
    "    input_shape=(256, 256, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the segmentation transform model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (2384, 256, 256, 2)\n",
      "y_train shape: (2384, 256, 256, 1)\n",
      "X_test shape: (265, 256, 256, 2)\n",
      "y_test shape: (265, 256, 256, 1)\n",
      "Output Shape: (None, 256, 256, 3)\n",
      "Number of Classes: 3\n",
      "Training on 1 GPUs\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1115 03:11:51.598669 140369887557440 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "   1/2384 [..............................] - ETA: 7:34:05 - loss: 5.5636 - model_loss: 1.3106 - model_1_loss: 1.4279 - model_2_loss: 1.4038 - model_3_loss: 1.3852 - model_acc: 0.2765 - model_1_acc: 0.4211 - model_2_acc: 0.1967 - model_3_acc: 0.1994"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1115 03:12:02.653802 140369887557440 callbacks.py:257] Method (on_train_batch_end) is slow compared to the batch update (0.224747). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2383/2384 [============================>.] - ETA: 0s - loss: 3.0129 - model_loss: 0.7618 - model_1_loss: 0.7537 - model_2_loss: 0.7374 - model_3_loss: 0.7222 - model_acc: 0.6397 - model_1_acc: 0.6364 - model_2_acc: 0.6503 - model_3_acc: 0.6583\n",
      "Epoch 00001: val_loss improved from inf to 3.17922, saving model to /data/analyses/featurenet/featurenet_split_3_redo.h5\n",
      "2384/2384 [==============================] - 323s 135ms/step - loss: 3.0127 - model_loss: 0.7617 - model_1_loss: 0.7536 - model_2_loss: 0.7374 - model_3_loss: 0.7222 - model_acc: 0.6397 - model_1_acc: 0.6365 - model_2_acc: 0.6504 - model_3_acc: 0.6583 - val_loss: 3.1792 - val_model_loss: 0.8149 - val_model_1_loss: 0.8162 - val_model_2_loss: 0.7520 - val_model_3_loss: 0.7580 - val_model_acc: 0.7099 - val_model_1_acc: 0.6992 - val_model_2_acc: 0.7000 - val_model_3_acc: 0.7048\n",
      "Epoch 2/25\n",
      "2383/2384 [============================>.] - ETA: 0s - loss: 2.6731 - model_loss: 0.6667 - model_1_loss: 0.6626 - model_2_loss: 0.6550 - model_3_loss: 0.6505 - model_acc: 0.6980 - model_1_acc: 0.6994 - model_2_acc: 0.7048 - model_3_acc: 0.7075\n",
      "Epoch 00002: val_loss did not improve from 3.17922\n",
      "2384/2384 [==============================] - 307s 129ms/step - loss: 2.6730 - model_loss: 0.6667 - model_1_loss: 0.6626 - model_2_loss: 0.6550 - model_3_loss: 0.6504 - model_acc: 0.6980 - model_1_acc: 0.6995 - model_2_acc: 0.7049 - model_3_acc: 0.7076 - val_loss: 3.4334 - val_model_loss: 0.8556 - val_model_1_loss: 0.8888 - val_model_2_loss: 0.8562 - val_model_3_loss: 0.7942 - val_model_acc: 0.7570 - val_model_1_acc: 0.7499 - val_model_2_acc: 0.7619 - val_model_3_acc: 0.7639\n",
      "Epoch 3/25\n",
      "2383/2384 [============================>.] - ETA: 0s - loss: 2.5655 - model_loss: 0.6370 - model_1_loss: 0.6336 - model_2_loss: 0.6300 - model_3_loss: 0.6261 - model_acc: 0.7176 - model_1_acc: 0.7220 - model_2_acc: 0.7228 - model_3_acc: 0.7239\n",
      "Epoch 00003: val_loss improved from 3.17922 to 2.88583, saving model to /data/analyses/featurenet/featurenet_split_3_redo.h5\n",
      "2384/2384 [==============================] - 305s 128ms/step - loss: 2.5654 - model_loss: 0.6369 - model_1_loss: 0.6336 - model_2_loss: 0.6300 - model_3_loss: 0.6260 - model_acc: 0.7176 - model_1_acc: 0.7220 - model_2_acc: 0.7227 - model_3_acc: 0.7238 - val_loss: 2.8858 - val_model_loss: 0.7172 - val_model_1_loss: 0.7302 - val_model_2_loss: 0.7005 - val_model_3_loss: 0.6989 - val_model_acc: 0.7277 - val_model_1_acc: 0.7260 - val_model_2_acc: 0.7340 - val_model_3_acc: 0.7259\n",
      "Epoch 4/25\n",
      "2383/2384 [============================>.] - ETA: 0s - loss: 2.5001 - model_loss: 0.6195 - model_1_loss: 0.6180 - model_2_loss: 0.6135 - model_3_loss: 0.6098 - model_acc: 0.7280 - model_1_acc: 0.7318 - model_2_acc: 0.7343 - model_3_acc: 0.7344\n",
      "Epoch 00004: val_loss improved from 2.88583 to 2.78427, saving model to /data/analyses/featurenet/featurenet_split_3_redo.h5\n",
      "2384/2384 [==============================] - 305s 128ms/step - loss: 2.4997 - model_loss: 0.6194 - model_1_loss: 0.6179 - model_2_loss: 0.6134 - model_3_loss: 0.6097 - model_acc: 0.7281 - model_1_acc: 0.7318 - model_2_acc: 0.7344 - model_3_acc: 0.7345 - val_loss: 2.7843 - val_model_loss: 0.7034 - val_model_1_loss: 0.6858 - val_model_2_loss: 0.6857 - val_model_3_loss: 0.6699 - val_model_acc: 0.7488 - val_model_1_acc: 0.7546 - val_model_2_acc: 0.7587 - val_model_3_acc: 0.7615\n",
      "Epoch 5/25\n",
      "2383/2384 [============================>.] - ETA: 0s - loss: 2.4673 - model_loss: 0.6113 - model_1_loss: 0.6077 - model_2_loss: 0.6058 - model_3_loss: 0.6028 - model_acc: 0.7333 - model_1_acc: 0.7385 - model_2_acc: 0.7391 - model_3_acc: 0.7391\n",
      "Epoch 00005: val_loss did not improve from 2.78427\n",
      "2384/2384 [==============================] - 305s 128ms/step - loss: 2.4673 - model_loss: 0.6113 - model_1_loss: 0.6077 - model_2_loss: 0.6058 - model_3_loss: 0.6028 - model_acc: 0.7333 - model_1_acc: 0.7385 - model_2_acc: 0.7391 - model_3_acc: 0.7391 - val_loss: 2.8572 - val_model_loss: 0.7097 - val_model_1_loss: 0.7229 - val_model_2_loss: 0.6920 - val_model_3_loss: 0.6928 - val_model_acc: 0.7523 - val_model_1_acc: 0.7614 - val_model_2_acc: 0.7615 - val_model_3_acc: 0.7670\n",
      "Epoch 6/25\n",
      "2383/2384 [============================>.] - ETA: 0s - loss: 2.4124 - model_loss: 0.5997 - model_1_loss: 0.5937 - model_2_loss: 0.5910 - model_3_loss: 0.5882 - model_acc: 0.7393 - model_1_acc: 0.7469 - model_2_acc: 0.7467 - model_3_acc: 0.7476\n",
      "Epoch 00006: val_loss did not improve from 2.78427\n",
      "2384/2384 [==============================] - 304s 128ms/step - loss: 2.4124 - model_loss: 0.5996 - model_1_loss: 0.5937 - model_2_loss: 0.5910 - model_3_loss: 0.5882 - model_acc: 0.7393 - model_1_acc: 0.7469 - model_2_acc: 0.7467 - model_3_acc: 0.7476 - val_loss: 3.0249 - val_model_loss: 0.7301 - val_model_1_loss: 0.7802 - val_model_2_loss: 0.7544 - val_model_3_loss: 0.7200 - val_model_acc: 0.7266 - val_model_1_acc: 0.7287 - val_model_2_acc: 0.6766 - val_model_3_acc: 0.7140\n",
      "Epoch 7/25\n",
      "2383/2384 [============================>.] - ETA: 0s - loss: 2.4091 - model_loss: 0.5959 - model_1_loss: 0.5894 - model_2_loss: 0.5952 - model_3_loss: 0.5882 - model_acc: 0.7428 - model_1_acc: 0.7496 - model_2_acc: 0.7472 - model_3_acc: 0.7483\n",
      "Epoch 00007: val_loss did not improve from 2.78427\n",
      "2384/2384 [==============================] - 304s 127ms/step - loss: 2.4088 - model_loss: 0.5959 - model_1_loss: 0.5894 - model_2_loss: 0.5951 - model_3_loss: 0.5882 - model_acc: 0.7428 - model_1_acc: 0.7496 - model_2_acc: 0.7472 - model_3_acc: 0.7483 - val_loss: 2.8704 - val_model_loss: 0.7345 - val_model_1_loss: 0.7279 - val_model_2_loss: 0.6915 - val_model_3_loss: 0.6760 - val_model_acc: 0.7416 - val_model_1_acc: 0.7472 - val_model_2_acc: 0.7497 - val_model_3_acc: 0.7447\n",
      "Epoch 8/25\n",
      "2383/2384 [============================>.] - ETA: 0s - loss: 2.3782 - model_loss: 0.5895 - model_1_loss: 0.5837 - model_2_loss: 0.5832 - model_3_loss: 0.5813 - model_acc: 0.7471 - model_1_acc: 0.7536 - model_2_acc: 0.7531 - model_3_acc: 0.7529\n",
      "Epoch 00008: val_loss did not improve from 2.78427\n",
      "2384/2384 [==============================] - 303s 127ms/step - loss: 2.3783 - model_loss: 0.5895 - model_1_loss: 0.5837 - model_2_loss: 0.5832 - model_3_loss: 0.5814 - model_acc: 0.7471 - model_1_acc: 0.7536 - model_2_acc: 0.7531 - model_3_acc: 0.7529 - val_loss: 2.9127 - val_model_loss: 0.6737 - val_model_1_loss: 0.7439 - val_model_2_loss: 0.7422 - val_model_3_loss: 0.7122 - val_model_acc: 0.7464 - val_model_1_acc: 0.7534 - val_model_2_acc: 0.7562 - val_model_3_acc: 0.7536\n",
      "Epoch 9/25\n",
      "2383/2384 [============================>.] - ETA: 0s - loss: 2.3579 - model_loss: 0.5861 - model_1_loss: 0.5784 - model_2_loss: 0.5771 - model_3_loss: 0.5755 - model_acc: 0.7488 - model_1_acc: 0.7556 - model_2_acc: 0.7553 - model_3_acc: 0.7557\n",
      "Epoch 00009: val_loss did not improve from 2.78427\n",
      "2384/2384 [==============================] - 303s 127ms/step - loss: 2.3582 - model_loss: 0.5862 - model_1_loss: 0.5785 - model_2_loss: 0.5772 - model_3_loss: 0.5755 - model_acc: 0.7488 - model_1_acc: 0.7556 - model_2_acc: 0.7552 - model_3_acc: 0.7557 - val_loss: 2.8842 - val_model_loss: 0.7526 - val_model_1_loss: 0.7256 - val_model_2_loss: 0.6875 - val_model_3_loss: 0.6776 - val_model_acc: 0.7242 - val_model_1_acc: 0.7352 - val_model_2_acc: 0.7390 - val_model_3_acc: 0.7355\n",
      "Epoch 10/25\n",
      "2383/2384 [============================>.] - ETA: 0s - loss: 2.3356 - model_loss: 0.5814 - model_1_loss: 0.5729 - model_2_loss: 0.5709 - model_3_loss: 0.5694 - model_acc: 0.7513 - model_1_acc: 0.7582 - model_2_acc: 0.7581 - model_3_acc: 0.7586\n",
      "Epoch 00010: val_loss improved from 2.78427 to 2.74173, saving model to /data/analyses/featurenet/featurenet_split_3_redo.h5\n",
      "2384/2384 [==============================] - 303s 127ms/step - loss: 2.3355 - model_loss: 0.5813 - model_1_loss: 0.5729 - model_2_loss: 0.5709 - model_3_loss: 0.5694 - model_acc: 0.7513 - model_1_acc: 0.7582 - model_2_acc: 0.7581 - model_3_acc: 0.7586 - val_loss: 2.7417 - val_model_loss: 0.6773 - val_model_1_loss: 0.6823 - val_model_2_loss: 0.6823 - val_model_3_loss: 0.6588 - val_model_acc: 0.7449 - val_model_1_acc: 0.7470 - val_model_2_acc: 0.7522 - val_model_3_acc: 0.7548\n",
      "Epoch 11/25\n",
      "2383/2384 [============================>.] - ETA: 0s - loss: 2.3164 - model_loss: 0.5769 - model_1_loss: 0.5676 - model_2_loss: 0.5658 - model_3_loss: 0.5648 - model_acc: 0.7531 - model_1_acc: 0.7620 - model_2_acc: 0.7611 - model_3_acc: 0.7616\n",
      "Epoch 00011: val_loss did not improve from 2.74173\n",
      "2384/2384 [==============================] - 303s 127ms/step - loss: 2.3165 - model_loss: 0.5770 - model_1_loss: 0.5676 - model_2_loss: 0.5659 - model_3_loss: 0.5649 - model_acc: 0.7531 - model_1_acc: 0.7620 - model_2_acc: 0.7611 - model_3_acc: 0.7615 - val_loss: 2.8521 - val_model_loss: 0.7140 - val_model_1_loss: 0.7238 - val_model_2_loss: 0.6761 - val_model_3_loss: 0.6969 - val_model_acc: 0.7388 - val_model_1_acc: 0.7288 - val_model_2_acc: 0.7412 - val_model_3_acc: 0.7269\n",
      "Epoch 12/25\n",
      "2383/2384 [============================>.] - ETA: 0s - loss: 2.3085 - model_loss: 0.5750 - model_1_loss: 0.5656 - model_2_loss: 0.5642 - model_3_loss: 0.5624 - model_acc: 0.7553 - model_1_acc: 0.7631 - model_2_acc: 0.7627 - model_3_acc: 0.7630\n",
      "Epoch 00012: val_loss did not improve from 2.74173\n",
      "2384/2384 [==============================] - 304s 127ms/step - loss: 2.3087 - model_loss: 0.5750 - model_1_loss: 0.5656 - model_2_loss: 0.5643 - model_3_loss: 0.5624 - model_acc: 0.7553 - model_1_acc: 0.7631 - model_2_acc: 0.7627 - model_3_acc: 0.7630 - val_loss: 3.6291 - val_model_loss: 0.9142 - val_model_1_loss: 0.9634 - val_model_2_loss: 0.8419 - val_model_3_loss: 0.8681 - val_model_acc: 0.6629 - val_model_1_acc: 0.6796 - val_model_2_acc: 0.6981 - val_model_3_acc: 0.6982\n",
      "Epoch 13/25\n",
      "2383/2384 [============================>.] - ETA: 0s - loss: 2.2925 - model_loss: 0.5715 - model_1_loss: 0.5609 - model_2_loss: 0.5599 - model_3_loss: 0.5586 - model_acc: 0.7561 - model_1_acc: 0.7648 - model_2_acc: 0.7641 - model_3_acc: 0.7647\n",
      "Epoch 00013: val_loss did not improve from 2.74173\n",
      "2384/2384 [==============================] - 303s 127ms/step - loss: 2.2926 - model_loss: 0.5716 - model_1_loss: 0.5609 - model_2_loss: 0.5599 - model_3_loss: 0.5586 - model_acc: 0.7561 - model_1_acc: 0.7648 - model_2_acc: 0.7641 - model_3_acc: 0.7646 - val_loss: 2.9608 - val_model_loss: 0.7011 - val_model_1_loss: 0.7607 - val_model_2_loss: 0.7472 - val_model_3_loss: 0.7101 - val_model_acc: 0.7328 - val_model_1_acc: 0.7279 - val_model_2_acc: 0.7420 - val_model_3_acc: 0.7396\n",
      "Epoch 14/25\n",
      "2383/2384 [============================>.] - ETA: 0s - loss: 2.2799 - model_loss: 0.5682 - model_1_loss: 0.5584 - model_2_loss: 0.5568 - model_3_loss: 0.5548 - model_acc: 0.7582 - model_1_acc: 0.7657 - model_2_acc: 0.7650 - model_3_acc: 0.7658\n",
      "Epoch 00014: val_loss did not improve from 2.74173\n",
      "2384/2384 [==============================] - 303s 127ms/step - loss: 2.2799 - model_loss: 0.5682 - model_1_loss: 0.5584 - model_2_loss: 0.5568 - model_3_loss: 0.5548 - model_acc: 0.7582 - model_1_acc: 0.7657 - model_2_acc: 0.7650 - model_3_acc: 0.7658 - val_loss: 3.0028 - val_model_loss: 0.7086 - val_model_1_loss: 0.7662 - val_model_2_loss: 0.7752 - val_model_3_loss: 0.7108 - val_model_acc: 0.7386 - val_model_1_acc: 0.7421 - val_model_2_acc: 0.7519 - val_model_3_acc: 0.7586\n",
      "Epoch 15/25\n",
      "2383/2384 [============================>.] - ETA: 0s - loss: 2.2702 - model_loss: 0.5653 - model_1_loss: 0.5553 - model_2_loss: 0.5546 - model_3_loss: 0.5531 - model_acc: 0.7602 - model_1_acc: 0.7682 - model_2_acc: 0.7671 - model_3_acc: 0.7678\n",
      "Epoch 00015: val_loss did not improve from 2.74173\n",
      "2384/2384 [==============================] - 303s 127ms/step - loss: 2.2705 - model_loss: 0.5654 - model_1_loss: 0.5553 - model_2_loss: 0.5546 - model_3_loss: 0.5532 - model_acc: 0.7602 - model_1_acc: 0.7682 - model_2_acc: 0.7671 - model_3_acc: 0.7678 - val_loss: 3.0909 - val_model_loss: 0.7445 - val_model_1_loss: 0.7551 - val_model_2_loss: 0.7930 - val_model_3_loss: 0.7564 - val_model_acc: 0.7460 - val_model_1_acc: 0.7412 - val_model_2_acc: 0.7348 - val_model_3_acc: 0.7347\n",
      "Epoch 16/25\n",
      "2383/2384 [============================>.] - ETA: 0s - loss: 2.2603 - model_loss: 0.5635 - model_1_loss: 0.5530 - model_2_loss: 0.5515 - model_3_loss: 0.5502 - model_acc: 0.7608 - model_1_acc: 0.7687 - model_2_acc: 0.7678 - model_3_acc: 0.7686\n",
      "Epoch 00016: val_loss did not improve from 2.74173\n",
      "2384/2384 [==============================] - 303s 127ms/step - loss: 2.2607 - model_loss: 0.5636 - model_1_loss: 0.5531 - model_2_loss: 0.5517 - model_3_loss: 0.5503 - model_acc: 0.7608 - model_1_acc: 0.7687 - model_2_acc: 0.7679 - model_3_acc: 0.7686 - val_loss: 2.7735 - val_model_loss: 0.6737 - val_model_1_loss: 0.6906 - val_model_2_loss: 0.6967 - val_model_3_loss: 0.6704 - val_model_acc: 0.7559 - val_model_1_acc: 0.7675 - val_model_2_acc: 0.7586 - val_model_3_acc: 0.7627\n",
      "Epoch 17/25\n",
      "2383/2384 [============================>.] - ETA: 0s - loss: 2.2548 - model_loss: 0.5623 - model_1_loss: 0.5517 - model_2_loss: 0.5505 - model_3_loss: 0.5481 - model_acc: 0.7609 - model_1_acc: 0.7693 - model_2_acc: 0.7684 - model_3_acc: 0.7694\n",
      "Epoch 00017: val_loss did not improve from 2.74173\n",
      "2384/2384 [==============================] - 303s 127ms/step - loss: 2.2547 - model_loss: 0.5623 - model_1_loss: 0.5517 - model_2_loss: 0.5505 - model_3_loss: 0.5480 - model_acc: 0.7609 - model_1_acc: 0.7693 - model_2_acc: 0.7684 - model_3_acc: 0.7694 - val_loss: 2.9323 - val_model_loss: 0.6994 - val_model_1_loss: 0.7414 - val_model_2_loss: 0.7423 - val_model_3_loss: 0.7069 - val_model_acc: 0.7571 - val_model_1_acc: 0.7558 - val_model_2_acc: 0.7538 - val_model_3_acc: 0.7537\n",
      "Epoch 18/25\n",
      "2383/2384 [============================>.] - ETA: 0s - loss: 2.2502 - model_loss: 0.5616 - model_1_loss: 0.5501 - model_2_loss: 0.5489 - model_3_loss: 0.5471 - model_acc: 0.7621 - model_1_acc: 0.7704 - model_2_acc: 0.7696 - model_3_acc: 0.7705\n",
      "Epoch 00018: val_loss did not improve from 2.74173\n",
      "2384/2384 [==============================] - 303s 127ms/step - loss: 2.2501 - model_loss: 0.5616 - model_1_loss: 0.5501 - model_2_loss: 0.5489 - model_3_loss: 0.5471 - model_acc: 0.7621 - model_1_acc: 0.7705 - model_2_acc: 0.7697 - model_3_acc: 0.7706 - val_loss: 3.0397 - val_model_loss: 0.7100 - val_model_1_loss: 0.7708 - val_model_2_loss: 0.7724 - val_model_3_loss: 0.7440 - val_model_acc: 0.7455 - val_model_1_acc: 0.7396 - val_model_2_acc: 0.7446 - val_model_3_acc: 0.7480\n",
      "Epoch 19/25\n",
      "2383/2384 [============================>.] - ETA: 0s - loss: 2.2363 - model_loss: 0.5583 - model_1_loss: 0.5466 - model_2_loss: 0.5450 - model_3_loss: 0.5439 - model_acc: 0.7637 - model_1_acc: 0.7716 - model_2_acc: 0.7712 - model_3_acc: 0.7721\n",
      "Epoch 00019: val_loss did not improve from 2.74173\n",
      "2384/2384 [==============================] - 303s 127ms/step - loss: 2.2362 - model_loss: 0.5582 - model_1_loss: 0.5465 - model_2_loss: 0.5450 - model_3_loss: 0.5439 - model_acc: 0.7638 - model_1_acc: 0.7716 - model_2_acc: 0.7712 - model_3_acc: 0.7721 - val_loss: 2.8195 - val_model_loss: 0.6732 - val_model_1_loss: 0.7112 - val_model_2_loss: 0.6844 - val_model_3_loss: 0.7081 - val_model_acc: 0.7511 - val_model_1_acc: 0.7574 - val_model_2_acc: 0.7541 - val_model_3_acc: 0.7484\n",
      "Epoch 20/25\n",
      "2383/2384 [============================>.] - ETA: 0s - loss: 2.2346 - model_loss: 0.5574 - model_1_loss: 0.5459 - model_2_loss: 0.5448 - model_3_loss: 0.5437 - model_acc: 0.7640 - model_1_acc: 0.7726 - model_2_acc: 0.7718 - model_3_acc: 0.7731\n",
      "Epoch 00020: val_loss did not improve from 2.74173\n",
      "2384/2384 [==============================] - 302s 127ms/step - loss: 2.2343 - model_loss: 0.5574 - model_1_loss: 0.5458 - model_2_loss: 0.5448 - model_3_loss: 0.5437 - model_acc: 0.7640 - model_1_acc: 0.7726 - model_2_acc: 0.7718 - model_3_acc: 0.7731 - val_loss: 2.8041 - val_model_loss: 0.6676 - val_model_1_loss: 0.7209 - val_model_2_loss: 0.6897 - val_model_3_loss: 0.6831 - val_model_acc: 0.7428 - val_model_1_acc: 0.7573 - val_model_2_acc: 0.7606 - val_model_3_acc: 0.7557\n",
      "Epoch 21/25\n",
      "2383/2384 [============================>.] - ETA: 0s - loss: 2.2246 - model_loss: 0.5566 - model_1_loss: 0.5434 - model_2_loss: 0.5420 - model_3_loss: 0.5398 - model_acc: 0.7652 - model_1_acc: 0.7731 - model_2_acc: 0.7729 - model_3_acc: 0.7736\n",
      "Epoch 00021: val_loss improved from 2.74173 to 2.58759, saving model to /data/analyses/featurenet/featurenet_split_3_redo.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2384/2384 [==============================] - 303s 127ms/step - loss: 2.2246 - model_loss: 0.5566 - model_1_loss: 0.5434 - model_2_loss: 0.5420 - model_3_loss: 0.5398 - model_acc: 0.7652 - model_1_acc: 0.7731 - model_2_acc: 0.7729 - model_3_acc: 0.7736 - val_loss: 2.5876 - val_model_loss: 0.6139 - val_model_1_loss: 0.6272 - val_model_2_loss: 0.6688 - val_model_3_loss: 0.6348 - val_model_acc: 0.7493 - val_model_1_acc: 0.7611 - val_model_2_acc: 0.7550 - val_model_3_acc: 0.7619\n",
      "Epoch 22/25\n",
      "2383/2384 [============================>.] - ETA: 0s - loss: 2.2348 - model_loss: 0.5585 - model_1_loss: 0.5462 - model_2_loss: 0.5444 - model_3_loss: 0.5427 - model_acc: 0.7652 - model_1_acc: 0.7738 - model_2_acc: 0.7734 - model_3_acc: 0.7739\n",
      "Epoch 00022: val_loss did not improve from 2.58759\n",
      "2384/2384 [==============================] - 303s 127ms/step - loss: 2.2345 - model_loss: 0.5585 - model_1_loss: 0.5461 - model_2_loss: 0.5443 - model_3_loss: 0.5426 - model_acc: 0.7652 - model_1_acc: 0.7738 - model_2_acc: 0.7734 - model_3_acc: 0.7739 - val_loss: 2.7947 - val_model_loss: 0.6551 - val_model_1_loss: 0.6881 - val_model_2_loss: 0.7060 - val_model_3_loss: 0.7026 - val_model_acc: 0.7590 - val_model_1_acc: 0.7582 - val_model_2_acc: 0.7523 - val_model_3_acc: 0.7438\n",
      "Epoch 23/25\n",
      "2383/2384 [============================>.] - ETA: 0s - loss: 2.2270 - model_loss: 0.5566 - model_1_loss: 0.5436 - model_2_loss: 0.5428 - model_3_loss: 0.5409 - model_acc: 0.7660 - model_1_acc: 0.7743 - model_2_acc: 0.7741 - model_3_acc: 0.7746\n",
      "Epoch 00023: val_loss did not improve from 2.58759\n",
      "2384/2384 [==============================] - 302s 127ms/step - loss: 2.2271 - model_loss: 0.5566 - model_1_loss: 0.5436 - model_2_loss: 0.5428 - model_3_loss: 0.5409 - model_acc: 0.7660 - model_1_acc: 0.7743 - model_2_acc: 0.7741 - model_3_acc: 0.7746 - val_loss: 2.8610 - val_model_loss: 0.6839 - val_model_1_loss: 0.7322 - val_model_2_loss: 0.7109 - val_model_3_loss: 0.6909 - val_model_acc: 0.7632 - val_model_1_acc: 0.7584 - val_model_2_acc: 0.7586 - val_model_3_acc: 0.7610\n",
      "Epoch 24/25\n",
      "2383/2384 [============================>.] - ETA: 0s - loss: 2.2105 - model_loss: 0.5528 - model_1_loss: 0.5397 - model_2_loss: 0.5384 - model_3_loss: 0.5365 - model_acc: 0.7670 - model_1_acc: 0.7756 - model_2_acc: 0.7752 - model_3_acc: 0.7755\n",
      "Epoch 00024: val_loss did not improve from 2.58759\n",
      "2384/2384 [==============================] - 303s 127ms/step - loss: 2.2106 - model_loss: 0.5528 - model_1_loss: 0.5397 - model_2_loss: 0.5384 - model_3_loss: 0.5365 - model_acc: 0.7670 - model_1_acc: 0.7756 - model_2_acc: 0.7752 - model_3_acc: 0.7755 - val_loss: 3.1073 - val_model_loss: 0.7284 - val_model_1_loss: 0.8157 - val_model_2_loss: 0.7455 - val_model_3_loss: 0.7745 - val_model_acc: 0.7334 - val_model_1_acc: 0.7448 - val_model_2_acc: 0.7497 - val_model_3_acc: 0.7474\n",
      "Epoch 25/25\n",
      "2383/2384 [============================>.] - ETA: 0s - loss: 2.2037 - model_loss: 0.5505 - model_1_loss: 0.5380 - model_2_loss: 0.5364 - model_3_loss: 0.5355 - model_acc: 0.7677 - model_1_acc: 0.7765 - model_2_acc: 0.7764 - model_3_acc: 0.7769\n",
      "Epoch 00025: val_loss did not improve from 2.58759\n",
      "2384/2384 [==============================] - 302s 127ms/step - loss: 2.2035 - model_loss: 0.5504 - model_1_loss: 0.5379 - model_2_loss: 0.5364 - model_3_loss: 0.5354 - model_acc: 0.7678 - model_1_acc: 0.7766 - model_2_acc: 0.7764 - model_3_acc: 0.7770 - val_loss: 2.8530 - val_model_loss: 0.6604 - val_model_1_loss: 0.7135 - val_model_2_loss: 0.7201 - val_model_3_loss: 0.7156 - val_model_acc: 0.7369 - val_model_1_acc: 0.7408 - val_model_2_acc: 0.7407 - val_model_3_acc: 0.7411\n"
     ]
    }
   ],
   "source": [
    "from deepcell.training import train_model_conv\n",
    "\n",
    "conv_model = train_model_conv(\n",
    "    model=conv_model,\n",
    "    dataset=DATA_FILE,  # full path to npz file\n",
    "    model_name=conv_model_name,\n",
    "    test_size=0.1,\n",
    "    seed=1,\n",
    "    transform=transform,\n",
    "    dilation_radius=dilation_radius,\n",
    "    separate_edge_classes=separate_edge_classes,\n",
    "    optimizer=optimizer,\n",
    "    batch_size=batch_size,\n",
    "    n_epoch=n_epoch,\n",
    "    log_dir=LOG_DIR,\n",
    "    model_dir=MODEL_DIR,\n",
    "    lr_sched=lr_sched,\n",
    "    rotation_range=180,\n",
    "    flip=True,\n",
    "    shear=False,\n",
    "    zoom_range=(0.7, 1/0.7))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
