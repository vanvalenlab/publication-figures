{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Convolutional Interior/Edge Segmentation for 2D Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook trains a featurenet model on the original data from Keren et al 2018\n",
    "import os\n",
    "import errno\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import deepcell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder for this set of experiments\n",
    "experiment_folder = \"featurenet_samir\"\n",
    "MODEL_DIR = os.path.join(\"/data/analyses\", experiment_folder)\n",
    "NPZ_DIR = \"/data/npz_data/\"\n",
    "LOG_DIR = '/data/logs'\n",
    "\n",
    "if not os.path.isdir(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up filepath constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "from deepcell.utils.train_utils import rate_scheduler\n",
    "\n",
    "conv_model_name = 'featurenet_samir'\n",
    "npz_name = \"samir_labels_256x256.npz\"\n",
    "DATA_FILE = os.path.join(NPZ_DIR, npz_name)\n",
    "\n",
    "n_epoch = 100  # Number of training epochs\n",
    "norm_method = 'whole_image'  # data normalization\n",
    "receptive_field = 61  # should be adjusted for the scale of the data\n",
    "\n",
    "optimizer = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "lr_sched = rate_scheduler(lr=0.01, decay=0.99)\n",
    "\n",
    "# FC training settings\n",
    "n_skips = 3  # number of skip-connections (only for FC training)\n",
    "batch_size = 1  # FC training uses 1 image per batch\n",
    "\n",
    "# Transformation settings\n",
    "transform = 'pixelwise'\n",
    "dilation_radius = 0  # change dilation radius for edge dilation\n",
    "separate_edge_classes = False  # break edges into cell-background edge, cell-cell edge\n",
    "n_features = 4 if separate_edge_classes else 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, Create a model for the edge/interior segmentation\n",
    "\n",
    "#### Instantiate the segmentation transform model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell import model_zoo\n",
    "\n",
    "conv_model = model_zoo.bn_feature_net_skip_2D(\n",
    "    receptive_field=receptive_field,\n",
    "    n_skips=n_skips,\n",
    "    n_features=n_features,\n",
    "    norm_method=norm_method,\n",
    "    n_conv_filters=32,\n",
    "    n_dense_filters=128,\n",
    "    last_only=False,\n",
    "    input_shape=(256, 256, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the segmentation transform model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (115, 256, 256, 1)\n",
      "y_train shape: (115, 256, 256, 1)\n",
      "X_test shape: (13, 256, 256, 1)\n",
      "y_test shape: (13, 256, 256, 1)\n",
      "Output Shape: (None, 256, 256, 3)\n",
      "Number of Classes: 3\n",
      "Training on 1 GPUs\n",
      "Epoch 1/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 3.0046 - model_5_loss: 0.7502 - model_6_loss: 0.7456 - model_7_loss: 0.7399 - model_8_loss: 0.7328 - model_5_acc: 0.7162 - model_6_acc: 0.7214 - model_7_acc: 0.7316 - model_8_acc: 0.7284\n",
      "Epoch 00001: val_loss improved from inf to 2.85959, saving model to /data/analyses/featurenet_samir/featurenet_samir.h5\n",
      "115/115 [==============================] - 31s 268ms/step - loss: 2.9985 - model_5_loss: 0.7487 - model_6_loss: 0.7440 - model_7_loss: 0.7385 - model_8_loss: 0.7312 - model_5_acc: 0.7169 - model_6_acc: 0.7221 - model_7_acc: 0.7322 - model_8_acc: 0.7290 - val_loss: 2.8596 - val_model_5_loss: 0.6779 - val_model_6_loss: 0.6660 - val_model_7_loss: 0.8330 - val_model_8_loss: 0.6465 - val_model_5_acc: 0.8133 - val_model_6_acc: 0.8119 - val_model_7_acc: 0.8005 - val_model_8_acc: 0.8077\n",
      "Epoch 2/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.4642 - model_5_loss: 0.6143 - model_6_loss: 0.6069 - model_7_loss: 0.6069 - model_8_loss: 0.5999 - model_5_acc: 0.7810 - model_6_acc: 0.7838 - model_7_acc: 0.7858 - model_8_acc: 0.7887\n",
      "Epoch 00002: val_loss improved from 2.85959 to 2.44358, saving model to /data/analyses/featurenet_samir/featurenet_samir.h5\n",
      "115/115 [==============================] - 16s 137ms/step - loss: 2.4611 - model_5_loss: 0.6136 - model_6_loss: 0.6062 - model_7_loss: 0.6060 - model_8_loss: 0.5991 - model_5_acc: 0.7813 - model_6_acc: 0.7840 - model_7_acc: 0.7861 - model_8_acc: 0.7891 - val_loss: 2.4436 - val_model_5_loss: 0.5997 - val_model_6_loss: 0.5824 - val_model_7_loss: 0.6550 - val_model_8_loss: 0.5703 - val_model_5_acc: 0.8052 - val_model_6_acc: 0.8120 - val_model_7_acc: 0.8153 - val_model_8_acc: 0.8087\n",
      "Epoch 3/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.3359 - model_5_loss: 0.5788 - model_6_loss: 0.5740 - model_7_loss: 0.5768 - model_8_loss: 0.5702 - model_5_acc: 0.7936 - model_6_acc: 0.7945 - model_7_acc: 0.7953 - model_8_acc: 0.7981\n",
      "Epoch 00003: val_loss improved from 2.44358 to 2.31341, saving model to /data/analyses/featurenet_samir/featurenet_samir.h5\n",
      "115/115 [==============================] - 16s 136ms/step - loss: 2.3341 - model_5_loss: 0.5783 - model_6_loss: 0.5735 - model_7_loss: 0.5763 - model_8_loss: 0.5698 - model_5_acc: 0.7937 - model_6_acc: 0.7947 - model_7_acc: 0.7954 - model_8_acc: 0.7983 - val_loss: 2.3134 - val_model_5_loss: 0.5741 - val_model_6_loss: 0.5699 - val_model_7_loss: 0.5767 - val_model_8_loss: 0.5565 - val_model_5_acc: 0.7875 - val_model_6_acc: 0.8016 - val_model_7_acc: 0.7953 - val_model_8_acc: 0.7872\n",
      "Epoch 4/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.3172 - model_5_loss: 0.5752 - model_6_loss: 0.5690 - model_7_loss: 0.5690 - model_8_loss: 0.5678 - model_5_acc: 0.7961 - model_6_acc: 0.7947 - model_7_acc: 0.7973 - model_8_acc: 0.7972\n",
      "Epoch 00004: val_loss improved from 2.31341 to 2.29811, saving model to /data/analyses/featurenet_samir/featurenet_samir.h5\n",
      "115/115 [==============================] - 16s 136ms/step - loss: 2.3168 - model_5_loss: 0.5749 - model_6_loss: 0.5691 - model_7_loss: 0.5690 - model_8_loss: 0.5677 - model_5_acc: 0.7963 - model_6_acc: 0.7949 - model_7_acc: 0.7975 - model_8_acc: 0.7974 - val_loss: 2.2981 - val_model_5_loss: 0.5694 - val_model_6_loss: 0.5676 - val_model_7_loss: 0.5719 - val_model_8_loss: 0.5529 - val_model_5_acc: 0.8145 - val_model_6_acc: 0.8108 - val_model_7_acc: 0.7998 - val_model_8_acc: 0.8082\n",
      "Epoch 5/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.2906 - model_5_loss: 0.5670 - model_6_loss: 0.5624 - model_7_loss: 0.5634 - model_8_loss: 0.5615 - model_5_acc: 0.7975 - model_6_acc: 0.7962 - model_7_acc: 0.7976 - model_8_acc: 0.7993\n",
      "Epoch 00005: val_loss improved from 2.29811 to 2.27421, saving model to /data/analyses/featurenet_samir/featurenet_samir.h5\n",
      "115/115 [==============================] - 16s 135ms/step - loss: 2.2893 - model_5_loss: 0.5667 - model_6_loss: 0.5621 - model_7_loss: 0.5630 - model_8_loss: 0.5613 - model_5_acc: 0.7977 - model_6_acc: 0.7965 - model_7_acc: 0.7979 - model_8_acc: 0.7994 - val_loss: 2.2742 - val_model_5_loss: 0.5491 - val_model_6_loss: 0.5642 - val_model_7_loss: 0.5699 - val_model_8_loss: 0.5548 - val_model_5_acc: 0.8068 - val_model_6_acc: 0.8099 - val_model_7_acc: 0.8047 - val_model_8_acc: 0.8032\n",
      "Epoch 6/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.2228 - model_5_loss: 0.5501 - model_6_loss: 0.5470 - model_7_loss: 0.5459 - model_8_loss: 0.5436 - model_5_acc: 0.8035 - model_6_acc: 0.8018 - model_7_acc: 0.8035 - model_8_acc: 0.8051\n",
      "Epoch 00006: val_loss improved from 2.27421 to 2.20679, saving model to /data/analyses/featurenet_samir/featurenet_samir.h5\n",
      "115/115 [==============================] - 16s 136ms/step - loss: 2.2244 - model_5_loss: 0.5505 - model_6_loss: 0.5474 - model_7_loss: 0.5462 - model_8_loss: 0.5440 - model_5_acc: 0.8035 - model_6_acc: 0.8019 - model_7_acc: 0.8034 - model_8_acc: 0.8051 - val_loss: 2.2068 - val_model_5_loss: 0.5422 - val_model_6_loss: 0.5424 - val_model_7_loss: 0.5494 - val_model_8_loss: 0.5365 - val_model_5_acc: 0.8113 - val_model_6_acc: 0.8041 - val_model_7_acc: 0.8133 - val_model_8_acc: 0.8040\n",
      "Epoch 7/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.2284 - model_5_loss: 0.5523 - model_6_loss: 0.5470 - model_7_loss: 0.5477 - model_8_loss: 0.5452 - model_5_acc: 0.8021 - model_6_acc: 0.8024 - model_7_acc: 0.8023 - model_8_acc: 0.8036\n",
      "Epoch 00007: val_loss improved from 2.20679 to 2.17111, saving model to /data/analyses/featurenet_samir/featurenet_samir.h5\n",
      "115/115 [==============================] - 16s 136ms/step - loss: 2.2248 - model_5_loss: 0.5513 - model_6_loss: 0.5461 - model_7_loss: 0.5469 - model_8_loss: 0.5444 - model_5_acc: 0.8026 - model_6_acc: 0.8029 - model_7_acc: 0.8027 - model_8_acc: 0.8040 - val_loss: 2.1711 - val_model_5_loss: 0.5373 - val_model_6_loss: 0.5333 - val_model_7_loss: 0.5370 - val_model_8_loss: 0.5274 - val_model_5_acc: 0.8158 - val_model_6_acc: 0.8083 - val_model_7_acc: 0.8062 - val_model_8_acc: 0.8101\n",
      "Epoch 8/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.2211 - model_5_loss: 0.5497 - model_6_loss: 0.5460 - model_7_loss: 0.5443 - model_8_loss: 0.5449 - model_5_acc: 0.8027 - model_6_acc: 0.8011 - model_7_acc: 0.8021 - model_8_acc: 0.8031\n",
      "Epoch 00008: val_loss improved from 2.17111 to 2.16959, saving model to /data/analyses/featurenet_samir/featurenet_samir.h5\n",
      "115/115 [==============================] - 16s 136ms/step - loss: 2.2203 - model_5_loss: 0.5495 - model_6_loss: 0.5458 - model_7_loss: 0.5441 - model_8_loss: 0.5447 - model_5_acc: 0.8029 - model_6_acc: 0.8012 - model_7_acc: 0.8023 - model_8_acc: 0.8032 - val_loss: 2.1696 - val_model_5_loss: 0.5415 - val_model_6_loss: 0.5334 - val_model_7_loss: 0.5383 - val_model_8_loss: 0.5202 - val_model_5_acc: 0.8081 - val_model_6_acc: 0.8117 - val_model_7_acc: 0.8060 - val_model_8_acc: 0.8052\n",
      "Epoch 9/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.1846 - model_5_loss: 0.5416 - model_6_loss: 0.5347 - model_7_loss: 0.5365 - model_8_loss: 0.5358 - model_5_acc: 0.8060 - model_6_acc: 0.8052 - model_7_acc: 0.8050 - model_8_acc: 0.8066\n",
      "Epoch 00009: val_loss did not improve from 2.16959\n",
      "115/115 [==============================] - 15s 134ms/step - loss: 2.1842 - model_5_loss: 0.5413 - model_6_loss: 0.5347 - model_7_loss: 0.5364 - model_8_loss: 0.5356 - model_5_acc: 0.8061 - model_6_acc: 0.8054 - model_7_acc: 0.8052 - model_8_acc: 0.8068 - val_loss: 2.2166 - val_model_5_loss: 0.5380 - val_model_6_loss: 0.5425 - val_model_7_loss: 0.5565 - val_model_8_loss: 0.5433 - val_model_5_acc: 0.8044 - val_model_6_acc: 0.7895 - val_model_7_acc: 0.7984 - val_model_8_acc: 0.8037\n",
      "Epoch 10/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.1801 - model_5_loss: 0.5414 - model_6_loss: 0.5342 - model_7_loss: 0.5350 - model_8_loss: 0.5333 - model_5_acc: 0.8055 - model_6_acc: 0.8059 - model_7_acc: 0.8059 - model_8_acc: 0.8068\n",
      "Epoch 00010: val_loss did not improve from 2.16959\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.1843 - model_5_loss: 0.5424 - model_6_loss: 0.5352 - model_7_loss: 0.5362 - model_8_loss: 0.5344 - model_5_acc: 0.8053 - model_6_acc: 0.8056 - model_7_acc: 0.8056 - model_8_acc: 0.8065 - val_loss: 2.1743 - val_model_5_loss: 0.5401 - val_model_6_loss: 0.5338 - val_model_7_loss: 0.5392 - val_model_8_loss: 0.5251 - val_model_5_acc: 0.8175 - val_model_6_acc: 0.8123 - val_model_7_acc: 0.8090 - val_model_8_acc: 0.8168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.2307 - model_5_loss: 0.5522 - model_6_loss: 0.5474 - model_7_loss: 0.5478 - model_8_loss: 0.5472 - model_5_acc: 0.8017 - model_6_acc: 0.8007 - model_7_acc: 0.8011 - model_8_acc: 0.8019\n",
      "Epoch 00011: val_loss did not improve from 2.16959\n",
      "115/115 [==============================] - 15s 134ms/step - loss: 2.2280 - model_5_loss: 0.5515 - model_6_loss: 0.5467 - model_7_loss: 0.5472 - model_8_loss: 0.5465 - model_5_acc: 0.8021 - model_6_acc: 0.8010 - model_7_acc: 0.8015 - model_8_acc: 0.8023 - val_loss: 2.1897 - val_model_5_loss: 0.5488 - val_model_6_loss: 0.5438 - val_model_7_loss: 0.5403 - val_model_8_loss: 0.5207 - val_model_5_acc: 0.8109 - val_model_6_acc: 0.8089 - val_model_7_acc: 0.8086 - val_model_8_acc: 0.8072\n",
      "Epoch 12/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.1661 - model_5_loss: 0.5365 - model_6_loss: 0.5320 - model_7_loss: 0.5311 - model_8_loss: 0.5304 - model_5_acc: 0.8068 - model_6_acc: 0.8059 - model_7_acc: 0.8066 - model_8_acc: 0.8081\n",
      "Epoch 00012: val_loss did not improve from 2.16959\n",
      "115/115 [==============================] - 15s 134ms/step - loss: 2.1646 - model_5_loss: 0.5361 - model_6_loss: 0.5316 - model_7_loss: 0.5307 - model_8_loss: 0.5301 - model_5_acc: 0.8070 - model_6_acc: 0.8061 - model_7_acc: 0.8068 - model_8_acc: 0.8083 - val_loss: 2.2168 - val_model_5_loss: 0.5435 - val_model_6_loss: 0.5411 - val_model_7_loss: 0.5323 - val_model_8_loss: 0.5639 - val_model_5_acc: 0.7930 - val_model_6_acc: 0.7863 - val_model_7_acc: 0.7832 - val_model_8_acc: 0.7861\n",
      "Epoch 13/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.1497 - model_5_loss: 0.5335 - model_6_loss: 0.5266 - model_7_loss: 0.5268 - model_8_loss: 0.5266 - model_5_acc: 0.8075 - model_6_acc: 0.8079 - model_7_acc: 0.8071 - model_8_acc: 0.8084\n",
      "Epoch 00013: val_loss did not improve from 2.16959\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.1474 - model_5_loss: 0.5330 - model_6_loss: 0.5260 - model_7_loss: 0.5262 - model_8_loss: 0.5261 - model_5_acc: 0.8078 - model_6_acc: 0.8082 - model_7_acc: 0.8075 - model_8_acc: 0.8087 - val_loss: 2.1750 - val_model_5_loss: 0.5391 - val_model_6_loss: 0.5423 - val_model_7_loss: 0.5336 - val_model_8_loss: 0.5239 - val_model_5_acc: 0.8033 - val_model_6_acc: 0.7896 - val_model_7_acc: 0.7975 - val_model_8_acc: 0.7913\n",
      "Epoch 14/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.1674 - model_5_loss: 0.5367 - model_6_loss: 0.5316 - model_7_loss: 0.5318 - model_8_loss: 0.5312 - model_5_acc: 0.8067 - model_6_acc: 0.8058 - model_7_acc: 0.8059 - model_8_acc: 0.8060\n",
      "Epoch 00014: val_loss improved from 2.16959 to 2.16682, saving model to /data/analyses/featurenet_samir/featurenet_samir.h5\n",
      "115/115 [==============================] - 16s 136ms/step - loss: 2.1654 - model_5_loss: 0.5362 - model_6_loss: 0.5311 - model_7_loss: 0.5312 - model_8_loss: 0.5307 - model_5_acc: 0.8069 - model_6_acc: 0.8060 - model_7_acc: 0.8061 - model_8_acc: 0.8062 - val_loss: 2.1668 - val_model_5_loss: 0.5427 - val_model_6_loss: 0.5346 - val_model_7_loss: 0.5312 - val_model_8_loss: 0.5222 - val_model_5_acc: 0.8033 - val_model_6_acc: 0.7944 - val_model_7_acc: 0.8007 - val_model_8_acc: 0.8017\n",
      "Epoch 15/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.1587 - model_5_loss: 0.5357 - model_6_loss: 0.5286 - model_7_loss: 0.5297 - model_8_loss: 0.5286 - model_5_acc: 0.8062 - model_6_acc: 0.8069 - model_7_acc: 0.8069 - model_8_acc: 0.8079\n",
      "Epoch 00015: val_loss improved from 2.16682 to 2.15378, saving model to /data/analyses/featurenet_samir/featurenet_samir.h5\n",
      "115/115 [==============================] - 16s 137ms/step - loss: 2.1599 - model_5_loss: 0.5360 - model_6_loss: 0.5289 - model_7_loss: 0.5300 - model_8_loss: 0.5289 - model_5_acc: 0.8059 - model_6_acc: 0.8066 - model_7_acc: 0.8065 - model_8_acc: 0.8075 - val_loss: 2.1538 - val_model_5_loss: 0.5436 - val_model_6_loss: 0.5206 - val_model_7_loss: 0.5301 - val_model_8_loss: 0.5234 - val_model_5_acc: 0.8068 - val_model_6_acc: 0.7989 - val_model_7_acc: 0.8060 - val_model_8_acc: 0.8045\n",
      "Epoch 16/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.1637 - model_5_loss: 0.5359 - model_6_loss: 0.5299 - model_7_loss: 0.5312 - model_8_loss: 0.5305 - model_5_acc: 0.8054 - model_6_acc: 0.8065 - model_7_acc: 0.8051 - model_8_acc: 0.8058\n",
      "Epoch 00016: val_loss did not improve from 2.15378\n",
      "115/115 [==============================] - 15s 134ms/step - loss: 2.1612 - model_5_loss: 0.5352 - model_6_loss: 0.5293 - model_7_loss: 0.5306 - model_8_loss: 0.5300 - model_5_acc: 0.8057 - model_6_acc: 0.8067 - model_7_acc: 0.8053 - model_8_acc: 0.8060 - val_loss: 2.1598 - val_model_5_loss: 0.5460 - val_model_6_loss: 0.5261 - val_model_7_loss: 0.5279 - val_model_8_loss: 0.5237 - val_model_5_acc: 0.8158 - val_model_6_acc: 0.8133 - val_model_7_acc: 0.8066 - val_model_8_acc: 0.8136\n",
      "Epoch 17/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.1326 - model_5_loss: 0.5291 - model_6_loss: 0.5222 - model_7_loss: 0.5226 - model_8_loss: 0.5226 - model_5_acc: 0.8082 - model_6_acc: 0.8090 - model_7_acc: 0.8086 - model_8_acc: 0.8095\n",
      "Epoch 00017: val_loss improved from 2.15378 to 2.11914, saving model to /data/analyses/featurenet_samir/featurenet_samir.h5\n",
      "115/115 [==============================] - 16s 136ms/step - loss: 2.1291 - model_5_loss: 0.5282 - model_6_loss: 0.5214 - model_7_loss: 0.5217 - model_8_loss: 0.5218 - model_5_acc: 0.8087 - model_6_acc: 0.8096 - model_7_acc: 0.8091 - model_8_acc: 0.8101 - val_loss: 2.1191 - val_model_5_loss: 0.5271 - val_model_6_loss: 0.5217 - val_model_7_loss: 0.5225 - val_model_8_loss: 0.5117 - val_model_5_acc: 0.8123 - val_model_6_acc: 0.8034 - val_model_7_acc: 0.8082 - val_model_8_acc: 0.8097\n",
      "Epoch 18/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.1603 - model_5_loss: 0.5359 - model_6_loss: 0.5305 - model_7_loss: 0.5294 - model_8_loss: 0.5285 - model_5_acc: 0.8054 - model_6_acc: 0.8054 - model_7_acc: 0.8058 - model_8_acc: 0.8061\n",
      "Epoch 00018: val_loss improved from 2.11914 to 2.11561, saving model to /data/analyses/featurenet_samir/featurenet_samir.h5\n",
      "115/115 [==============================] - 16s 136ms/step - loss: 2.1579 - model_5_loss: 0.5354 - model_6_loss: 0.5298 - model_7_loss: 0.5289 - model_8_loss: 0.5278 - model_5_acc: 0.8056 - model_6_acc: 0.8057 - model_7_acc: 0.8060 - model_8_acc: 0.8064 - val_loss: 2.1156 - val_model_5_loss: 0.5258 - val_model_6_loss: 0.5214 - val_model_7_loss: 0.5183 - val_model_8_loss: 0.5140 - val_model_5_acc: 0.8112 - val_model_6_acc: 0.8129 - val_model_7_acc: 0.8148 - val_model_8_acc: 0.8113\n",
      "Epoch 19/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.1343 - model_5_loss: 0.5292 - model_6_loss: 0.5230 - model_7_loss: 0.5229 - model_8_loss: 0.5230 - model_5_acc: 0.8087 - model_6_acc: 0.8093 - model_7_acc: 0.8087 - model_8_acc: 0.8090\n",
      "Epoch 00019: val_loss did not improve from 2.11561\n",
      "115/115 [==============================] - 15s 134ms/step - loss: 2.1306 - model_5_loss: 0.5283 - model_6_loss: 0.5220 - model_7_loss: 0.5220 - model_8_loss: 0.5221 - model_5_acc: 0.8092 - model_6_acc: 0.8099 - model_7_acc: 0.8093 - model_8_acc: 0.8095 - val_loss: 2.1747 - val_model_5_loss: 0.5392 - val_model_6_loss: 0.5353 - val_model_7_loss: 0.5253 - val_model_8_loss: 0.5387 - val_model_5_acc: 0.8079 - val_model_6_acc: 0.8085 - val_model_7_acc: 0.8148 - val_model_8_acc: 0.8012\n",
      "Epoch 20/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.1372 - model_5_loss: 0.5288 - model_6_loss: 0.5241 - model_7_loss: 0.5237 - model_8_loss: 0.5245 - model_5_acc: 0.8062 - model_6_acc: 0.8057 - model_7_acc: 0.8061 - model_8_acc: 0.8064\n",
      "Epoch 00020: val_loss did not improve from 2.11561\n",
      "115/115 [==============================] - 15s 134ms/step - loss: 2.1382 - model_5_loss: 0.5289 - model_6_loss: 0.5244 - model_7_loss: 0.5241 - model_8_loss: 0.5248 - model_5_acc: 0.8062 - model_6_acc: 0.8058 - model_7_acc: 0.8061 - model_8_acc: 0.8063 - val_loss: 2.1441 - val_model_5_loss: 0.5320 - val_model_6_loss: 0.5287 - val_model_7_loss: 0.5333 - val_model_8_loss: 0.5140 - val_model_5_acc: 0.8148 - val_model_6_acc: 0.8209 - val_model_7_acc: 0.8104 - val_model_8_acc: 0.8154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.1069 - model_5_loss: 0.5233 - model_6_loss: 0.5163 - model_7_loss: 0.5158 - model_8_loss: 0.5154 - model_5_acc: 0.8109 - model_6_acc: 0.8115 - model_7_acc: 0.8107 - model_8_acc: 0.8115\n",
      "Epoch 00021: val_loss improved from 2.11561 to 2.09358, saving model to /data/analyses/featurenet_samir/featurenet_samir.h5\n",
      "115/115 [==============================] - 16s 136ms/step - loss: 2.1075 - model_5_loss: 0.5235 - model_6_loss: 0.5165 - model_7_loss: 0.5159 - model_8_loss: 0.5155 - model_5_acc: 0.8108 - model_6_acc: 0.8114 - model_7_acc: 0.8106 - model_8_acc: 0.8114 - val_loss: 2.0936 - val_model_5_loss: 0.5166 - val_model_6_loss: 0.5147 - val_model_7_loss: 0.5172 - val_model_8_loss: 0.5091 - val_model_5_acc: 0.8129 - val_model_6_acc: 0.8030 - val_model_7_acc: 0.8058 - val_model_8_acc: 0.8068\n",
      "Epoch 22/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0978 - model_5_loss: 0.5207 - model_6_loss: 0.5140 - model_7_loss: 0.5134 - model_8_loss: 0.5137 - model_5_acc: 0.8115 - model_6_acc: 0.8125 - model_7_acc: 0.8120 - model_8_acc: 0.8120\n",
      "Epoch 00022: val_loss improved from 2.09358 to 2.09130, saving model to /data/analyses/featurenet_samir/featurenet_samir.h5\n",
      "115/115 [==============================] - 16s 135ms/step - loss: 2.0999 - model_5_loss: 0.5212 - model_6_loss: 0.5145 - model_7_loss: 0.5139 - model_8_loss: 0.5142 - model_5_acc: 0.8112 - model_6_acc: 0.8122 - model_7_acc: 0.8116 - model_8_acc: 0.8116 - val_loss: 2.0913 - val_model_5_loss: 0.5226 - val_model_6_loss: 0.5187 - val_model_7_loss: 0.5101 - val_model_8_loss: 0.5038 - val_model_5_acc: 0.8138 - val_model_6_acc: 0.8150 - val_model_7_acc: 0.8119 - val_model_8_acc: 0.8196\n",
      "Epoch 23/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.1099 - model_5_loss: 0.5225 - model_6_loss: 0.5173 - model_7_loss: 0.5174 - model_8_loss: 0.5166 - model_5_acc: 0.8090 - model_6_acc: 0.8091 - model_7_acc: 0.8089 - model_8_acc: 0.8094\n",
      "Epoch 00023: val_loss did not improve from 2.09130\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.1060 - model_5_loss: 0.5216 - model_6_loss: 0.5163 - model_7_loss: 0.5164 - model_8_loss: 0.5157 - model_5_acc: 0.8094 - model_6_acc: 0.8095 - model_7_acc: 0.8094 - model_8_acc: 0.8098 - val_loss: 2.1021 - val_model_5_loss: 0.5199 - val_model_6_loss: 0.5151 - val_model_7_loss: 0.5223 - val_model_8_loss: 0.5088 - val_model_5_acc: 0.8072 - val_model_6_acc: 0.8062 - val_model_7_acc: 0.8075 - val_model_8_acc: 0.8066\n",
      "Epoch 24/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.1095 - model_5_loss: 0.5237 - model_6_loss: 0.5166 - model_7_loss: 0.5167 - model_8_loss: 0.5165 - model_5_acc: 0.8090 - model_6_acc: 0.8100 - model_7_acc: 0.8096 - model_8_acc: 0.8100\n",
      "Epoch 00024: val_loss did not improve from 2.09130\n",
      "115/115 [==============================] - 15s 134ms/step - loss: 2.1103 - model_5_loss: 0.5238 - model_6_loss: 0.5168 - model_7_loss: 0.5169 - model_8_loss: 0.5167 - model_5_acc: 0.8086 - model_6_acc: 0.8096 - model_7_acc: 0.8092 - model_8_acc: 0.8096 - val_loss: 2.1264 - val_model_5_loss: 0.5425 - val_model_6_loss: 0.5167 - val_model_7_loss: 0.5161 - val_model_8_loss: 0.5151 - val_model_5_acc: 0.8134 - val_model_6_acc: 0.8099 - val_model_7_acc: 0.8149 - val_model_8_acc: 0.8129\n",
      "Epoch 25/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0966 - model_5_loss: 0.5211 - model_6_loss: 0.5140 - model_7_loss: 0.5130 - model_8_loss: 0.5125 - model_5_acc: 0.8107 - model_6_acc: 0.8121 - model_7_acc: 0.8113 - model_8_acc: 0.8122\n",
      "Epoch 00025: val_loss did not improve from 2.09130\n",
      "115/115 [==============================] - 15s 134ms/step - loss: 2.0974 - model_5_loss: 0.5213 - model_6_loss: 0.5142 - model_7_loss: 0.5132 - model_8_loss: 0.5126 - model_5_acc: 0.8105 - model_6_acc: 0.8119 - model_7_acc: 0.8111 - model_8_acc: 0.8120 - val_loss: 2.1092 - val_model_5_loss: 0.5229 - val_model_6_loss: 0.5172 - val_model_7_loss: 0.5209 - val_model_8_loss: 0.5122 - val_model_5_acc: 0.8118 - val_model_6_acc: 0.8018 - val_model_7_acc: 0.7968 - val_model_8_acc: 0.8017\n",
      "Epoch 26/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.1124 - model_5_loss: 0.5241 - model_6_loss: 0.5174 - model_7_loss: 0.5171 - model_8_loss: 0.5177 - model_5_acc: 0.8097 - model_6_acc: 0.8109 - model_7_acc: 0.8099 - model_8_acc: 0.8104\n",
      "Epoch 00026: val_loss did not improve from 2.09130\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.1096 - model_5_loss: 0.5235 - model_6_loss: 0.5167 - model_7_loss: 0.5164 - model_8_loss: 0.5170 - model_5_acc: 0.8099 - model_6_acc: 0.8110 - model_7_acc: 0.8100 - model_8_acc: 0.8106 - val_loss: 2.1057 - val_model_5_loss: 0.5250 - val_model_6_loss: 0.5152 - val_model_7_loss: 0.5203 - val_model_8_loss: 0.5092 - val_model_5_acc: 0.8211 - val_model_6_acc: 0.8167 - val_model_7_acc: 0.8258 - val_model_8_acc: 0.8188\n",
      "Epoch 27/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0818 - model_5_loss: 0.5172 - model_6_loss: 0.5098 - model_7_loss: 0.5095 - model_8_loss: 0.5093 - model_5_acc: 0.8121 - model_6_acc: 0.8124 - model_7_acc: 0.8117 - model_8_acc: 0.8126\n",
      "Epoch 00027: val_loss did not improve from 2.09130\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.1071 - model_5_loss: 0.5232 - model_6_loss: 0.5161 - model_7_loss: 0.5161 - model_8_loss: 0.5156 - model_5_acc: 0.8102 - model_6_acc: 0.8103 - model_7_acc: 0.8096 - model_8_acc: 0.8105 - val_loss: 2.1307 - val_model_5_loss: 0.5354 - val_model_6_loss: 0.5206 - val_model_7_loss: 0.5287 - val_model_8_loss: 0.5099 - val_model_5_acc: 0.8145 - val_model_6_acc: 0.8072 - val_model_7_acc: 0.8130 - val_model_8_acc: 0.8084\n",
      "Epoch 28/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.1273 - model_5_loss: 0.5269 - model_6_loss: 0.5216 - model_7_loss: 0.5214 - model_8_loss: 0.5212 - model_5_acc: 0.8063 - model_6_acc: 0.8074 - model_7_acc: 0.8067 - model_8_acc: 0.8073\n",
      "Epoch 00028: val_loss did not improve from 2.09130\n",
      "115/115 [==============================] - 15s 134ms/step - loss: 2.1247 - model_5_loss: 0.5263 - model_6_loss: 0.5210 - model_7_loss: 0.5208 - model_8_loss: 0.5206 - model_5_acc: 0.8067 - model_6_acc: 0.8077 - model_7_acc: 0.8071 - model_8_acc: 0.8077 - val_loss: 2.1047 - val_model_5_loss: 0.5331 - val_model_6_loss: 0.5138 - val_model_7_loss: 0.5127 - val_model_8_loss: 0.5091 - val_model_5_acc: 0.8199 - val_model_6_acc: 0.8152 - val_model_7_acc: 0.8114 - val_model_8_acc: 0.8190\n",
      "Epoch 29/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0817 - model_5_loss: 0.5161 - model_6_loss: 0.5098 - model_7_loss: 0.5102 - model_8_loss: 0.5095 - model_5_acc: 0.8109 - model_6_acc: 0.8111 - model_7_acc: 0.8107 - model_8_acc: 0.8113\n",
      "Epoch 00029: val_loss improved from 2.09130 to 2.08113, saving model to /data/analyses/featurenet_samir/featurenet_samir.h5\n",
      "115/115 [==============================] - 16s 136ms/step - loss: 2.0815 - model_5_loss: 0.5161 - model_6_loss: 0.5097 - model_7_loss: 0.5102 - model_8_loss: 0.5094 - model_5_acc: 0.8108 - model_6_acc: 0.8110 - model_7_acc: 0.8107 - model_8_acc: 0.8113 - val_loss: 2.0811 - val_model_5_loss: 0.5182 - val_model_6_loss: 0.5110 - val_model_7_loss: 0.5091 - val_model_8_loss: 0.5067 - val_model_5_acc: 0.8163 - val_model_6_acc: 0.8110 - val_model_7_acc: 0.8134 - val_model_8_acc: 0.8121\n",
      "Epoch 30/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0910 - model_5_loss: 0.5194 - model_6_loss: 0.5118 - model_7_loss: 0.5114 - model_8_loss: 0.5122 - model_5_acc: 0.8095 - model_6_acc: 0.8111 - model_7_acc: 0.8103 - model_8_acc: 0.8109\n",
      "Epoch 00030: val_loss did not improve from 2.08113\n",
      "115/115 [==============================] - 15s 134ms/step - loss: 2.0924 - model_5_loss: 0.5197 - model_6_loss: 0.5122 - model_7_loss: 0.5118 - model_8_loss: 0.5126 - model_5_acc: 0.8093 - model_6_acc: 0.8108 - model_7_acc: 0.8101 - model_8_acc: 0.8106 - val_loss: 2.1211 - val_model_5_loss: 0.5299 - val_model_6_loss: 0.5156 - val_model_7_loss: 0.5291 - val_model_8_loss: 0.5104 - val_model_5_acc: 0.8092 - val_model_6_acc: 0.8047 - val_model_7_acc: 0.7906 - val_model_8_acc: 0.8121\n",
      "Epoch 31/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.1099 - model_5_loss: 0.5231 - model_6_loss: 0.5166 - model_7_loss: 0.5170 - model_8_loss: 0.5172 - model_5_acc: 0.8090 - model_6_acc: 0.8095 - model_7_acc: 0.8088 - model_8_acc: 0.8098\n",
      "Epoch 00031: val_loss did not improve from 2.08113\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.1092 - model_5_loss: 0.5230 - model_6_loss: 0.5164 - model_7_loss: 0.5168 - model_8_loss: 0.5170 - model_5_acc: 0.8090 - model_6_acc: 0.8096 - model_7_acc: 0.8088 - model_8_acc: 0.8098 - val_loss: 2.1314 - val_model_5_loss: 0.5301 - val_model_6_loss: 0.5225 - val_model_7_loss: 0.5282 - val_model_8_loss: 0.5146 - val_model_5_acc: 0.8189 - val_model_6_acc: 0.8177 - val_model_7_acc: 0.8206 - val_model_8_acc: 0.8249\n",
      "Epoch 32/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0908 - model_5_loss: 0.5194 - model_6_loss: 0.5124 - model_7_loss: 0.5116 - model_8_loss: 0.5115 - model_5_acc: 0.8095 - model_6_acc: 0.8110 - model_7_acc: 0.8101 - model_8_acc: 0.8103\n",
      "Epoch 00032: val_loss did not improve from 2.08113\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0903 - model_5_loss: 0.5193 - model_6_loss: 0.5122 - model_7_loss: 0.5114 - model_8_loss: 0.5114 - model_5_acc: 0.8095 - model_6_acc: 0.8110 - model_7_acc: 0.8100 - model_8_acc: 0.8101 - val_loss: 2.1518 - val_model_5_loss: 0.5254 - val_model_6_loss: 0.5305 - val_model_7_loss: 0.5269 - val_model_8_loss: 0.5330 - val_model_5_acc: 0.8184 - val_model_6_acc: 0.8209 - val_model_7_acc: 0.8134 - val_model_8_acc: 0.8171\n",
      "Epoch 33/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0719 - model_5_loss: 0.5143 - model_6_loss: 0.5068 - model_7_loss: 0.5071 - model_8_loss: 0.5076 - model_5_acc: 0.8118 - model_6_acc: 0.8125 - model_7_acc: 0.8120 - model_8_acc: 0.8125\n",
      "Epoch 00033: val_loss did not improve from 2.08113\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0735 - model_5_loss: 0.5146 - model_6_loss: 0.5073 - model_7_loss: 0.5075 - model_8_loss: 0.5081 - model_5_acc: 0.8117 - model_6_acc: 0.8123 - model_7_acc: 0.8118 - model_8_acc: 0.8124 - val_loss: 2.1053 - val_model_5_loss: 0.5221 - val_model_6_loss: 0.5254 - val_model_7_loss: 0.5132 - val_model_8_loss: 0.5086 - val_model_5_acc: 0.8089 - val_model_6_acc: 0.8073 - val_model_7_acc: 0.8027 - val_model_8_acc: 0.8081\n",
      "Epoch 34/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0904 - model_5_loss: 0.5179 - model_6_loss: 0.5117 - model_7_loss: 0.5126 - model_8_loss: 0.5123 - model_5_acc: 0.8101 - model_6_acc: 0.8114 - model_7_acc: 0.8108 - model_8_acc: 0.8114\n",
      "Epoch 00034: val_loss improved from 2.08113 to 2.08008, saving model to /data/analyses/featurenet_samir/featurenet_samir.h5\n",
      "115/115 [==============================] - 16s 135ms/step - loss: 2.0882 - model_5_loss: 0.5173 - model_6_loss: 0.5111 - model_7_loss: 0.5120 - model_8_loss: 0.5117 - model_5_acc: 0.8104 - model_6_acc: 0.8117 - model_7_acc: 0.8111 - model_8_acc: 0.8116 - val_loss: 2.0801 - val_model_5_loss: 0.5155 - val_model_6_loss: 0.5102 - val_model_7_loss: 0.5127 - val_model_8_loss: 0.5057 - val_model_5_acc: 0.8147 - val_model_6_acc: 0.8132 - val_model_7_acc: 0.8191 - val_model_8_acc: 0.8190\n",
      "Epoch 35/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0857 - model_5_loss: 0.5173 - model_6_loss: 0.5108 - model_7_loss: 0.5111 - model_8_loss: 0.5105 - model_5_acc: 0.8091 - model_6_acc: 0.8111 - model_7_acc: 0.8100 - model_8_acc: 0.8110\n",
      "Epoch 00035: val_loss did not improve from 2.08008\n",
      "115/115 [==============================] - 15s 135ms/step - loss: 2.0816 - model_5_loss: 0.5163 - model_6_loss: 0.5098 - model_7_loss: 0.5100 - model_8_loss: 0.5095 - model_5_acc: 0.8095 - model_6_acc: 0.8115 - model_7_acc: 0.8104 - model_8_acc: 0.8114 - val_loss: 2.1036 - val_model_5_loss: 0.5253 - val_model_6_loss: 0.5150 - val_model_7_loss: 0.5121 - val_model_8_loss: 0.5151 - val_model_5_acc: 0.8121 - val_model_6_acc: 0.8096 - val_model_7_acc: 0.8076 - val_model_8_acc: 0.8102\n",
      "Epoch 36/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0863 - model_5_loss: 0.5178 - model_6_loss: 0.5104 - model_7_loss: 0.5113 - model_8_loss: 0.5108 - model_5_acc: 0.8105 - model_6_acc: 0.8109 - model_7_acc: 0.8105 - model_8_acc: 0.8110\n",
      "Epoch 00036: val_loss did not improve from 2.08008\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0820 - model_5_loss: 0.5167 - model_6_loss: 0.5093 - model_7_loss: 0.5102 - model_8_loss: 0.5098 - model_5_acc: 0.8110 - model_6_acc: 0.8114 - model_7_acc: 0.8110 - model_8_acc: 0.8115 - val_loss: 2.0839 - val_model_5_loss: 0.5163 - val_model_6_loss: 0.5076 - val_model_7_loss: 0.5163 - val_model_8_loss: 0.5077 - val_model_5_acc: 0.8125 - val_model_6_acc: 0.8131 - val_model_7_acc: 0.8119 - val_model_8_acc: 0.8108\n",
      "Epoch 37/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0974 - model_5_loss: 0.5204 - model_6_loss: 0.5138 - model_7_loss: 0.5141 - model_8_loss: 0.5132 - model_5_acc: 0.8078 - model_6_acc: 0.8103 - model_7_acc: 0.8098 - model_8_acc: 0.8104\n",
      "Epoch 00037: val_loss improved from 2.08008 to 2.06328, saving model to /data/analyses/featurenet_samir/featurenet_samir.h5\n",
      "115/115 [==============================] - 16s 135ms/step - loss: 2.0944 - model_5_loss: 0.5197 - model_6_loss: 0.5130 - model_7_loss: 0.5133 - model_8_loss: 0.5125 - model_5_acc: 0.8081 - model_6_acc: 0.8106 - model_7_acc: 0.8101 - model_8_acc: 0.8107 - val_loss: 2.0633 - val_model_5_loss: 0.5157 - val_model_6_loss: 0.5063 - val_model_7_loss: 0.5063 - val_model_8_loss: 0.4991 - val_model_5_acc: 0.8181 - val_model_6_acc: 0.8188 - val_model_7_acc: 0.8175 - val_model_8_acc: 0.8135\n",
      "Epoch 38/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.1015 - model_5_loss: 0.5210 - model_6_loss: 0.5149 - model_7_loss: 0.5152 - model_8_loss: 0.5144 - model_5_acc: 0.8099 - model_6_acc: 0.8109 - model_7_acc: 0.8098 - model_8_acc: 0.8107\n",
      "Epoch 00038: val_loss did not improve from 2.06328\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0973 - model_5_loss: 0.5200 - model_6_loss: 0.5139 - model_7_loss: 0.5141 - model_8_loss: 0.5133 - model_5_acc: 0.8103 - model_6_acc: 0.8113 - model_7_acc: 0.8102 - model_8_acc: 0.8111 - val_loss: 2.0656 - val_model_5_loss: 0.5182 - val_model_6_loss: 0.5038 - val_model_7_loss: 0.5037 - val_model_8_loss: 0.5040 - val_model_5_acc: 0.8038 - val_model_6_acc: 0.8020 - val_model_7_acc: 0.8035 - val_model_8_acc: 0.8024\n",
      "Epoch 39/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.1211 - model_5_loss: 0.5277 - model_6_loss: 0.5206 - model_7_loss: 0.5180 - model_8_loss: 0.5189 - model_5_acc: 0.8090 - model_6_acc: 0.8082 - model_7_acc: 0.8097 - model_8_acc: 0.8097\n",
      "Epoch 00039: val_loss did not improve from 2.06328\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.1207 - model_5_loss: 0.5276 - model_6_loss: 0.5204 - model_7_loss: 0.5179 - model_8_loss: 0.5187 - model_5_acc: 0.8088 - model_6_acc: 0.8080 - model_7_acc: 0.8095 - model_8_acc: 0.8095 - val_loss: 2.0863 - val_model_5_loss: 0.5221 - val_model_6_loss: 0.5161 - val_model_7_loss: 0.5031 - val_model_8_loss: 0.5091 - val_model_5_acc: 0.7986 - val_model_6_acc: 0.8018 - val_model_7_acc: 0.8042 - val_model_8_acc: 0.8044\n",
      "Epoch 40/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0946 - model_5_loss: 0.5207 - model_6_loss: 0.5129 - model_7_loss: 0.5123 - model_8_loss: 0.5128 - model_5_acc: 0.8106 - model_6_acc: 0.8127 - model_7_acc: 0.8113 - model_8_acc: 0.8114\n",
      "Epoch 00040: val_loss improved from 2.06328 to 2.06013, saving model to /data/analyses/featurenet_samir/featurenet_samir.h5\n",
      "115/115 [==============================] - 16s 136ms/step - loss: 2.0987 - model_5_loss: 0.5218 - model_6_loss: 0.5139 - model_7_loss: 0.5133 - model_8_loss: 0.5138 - model_5_acc: 0.8099 - model_6_acc: 0.8120 - model_7_acc: 0.8107 - model_8_acc: 0.8107 - val_loss: 2.0601 - val_model_5_loss: 0.5092 - val_model_6_loss: 0.5133 - val_model_7_loss: 0.4989 - val_model_8_loss: 0.5028 - val_model_5_acc: 0.8156 - val_model_6_acc: 0.8107 - val_model_7_acc: 0.8124 - val_model_8_acc: 0.8147\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/115 [============================>.] - ETA: 0s - loss: 2.0830 - model_5_loss: 0.5177 - model_6_loss: 0.5105 - model_7_loss: 0.5091 - model_8_loss: 0.5098 - model_5_acc: 0.8103 - model_6_acc: 0.8123 - model_7_acc: 0.8111 - model_8_acc: 0.8106\n",
      "Epoch 00041: val_loss did not improve from 2.06013\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0802 - model_5_loss: 0.5170 - model_6_loss: 0.5097 - model_7_loss: 0.5083 - model_8_loss: 0.5091 - model_5_acc: 0.8106 - model_6_acc: 0.8126 - model_7_acc: 0.8115 - model_8_acc: 0.8109 - val_loss: 2.0643 - val_model_5_loss: 0.5054 - val_model_6_loss: 0.5075 - val_model_7_loss: 0.5068 - val_model_8_loss: 0.5087 - val_model_5_acc: 0.8125 - val_model_6_acc: 0.8101 - val_model_7_acc: 0.8176 - val_model_8_acc: 0.8124\n",
      "Epoch 42/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0695 - model_5_loss: 0.5129 - model_6_loss: 0.5069 - model_7_loss: 0.5067 - model_8_loss: 0.5070 - model_5_acc: 0.8118 - model_6_acc: 0.8130 - model_7_acc: 0.8119 - model_8_acc: 0.8120\n",
      "Epoch 00042: val_loss improved from 2.06013 to 2.03945, saving model to /data/analyses/featurenet_samir/featurenet_samir.h5\n",
      "115/115 [==============================] - 16s 135ms/step - loss: 2.0670 - model_5_loss: 0.5123 - model_6_loss: 0.5063 - model_7_loss: 0.5061 - model_8_loss: 0.5064 - model_5_acc: 0.8119 - model_6_acc: 0.8131 - model_7_acc: 0.8121 - model_8_acc: 0.8121 - val_loss: 2.0394 - val_model_5_loss: 0.5008 - val_model_6_loss: 0.5045 - val_model_7_loss: 0.4982 - val_model_8_loss: 0.4999 - val_model_5_acc: 0.8155 - val_model_6_acc: 0.8094 - val_model_7_acc: 0.8106 - val_model_8_acc: 0.8119\n",
      "Epoch 43/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0762 - model_5_loss: 0.5148 - model_6_loss: 0.5090 - model_7_loss: 0.5083 - model_8_loss: 0.5080 - model_5_acc: 0.8105 - model_6_acc: 0.8124 - model_7_acc: 0.8112 - model_8_acc: 0.8116\n",
      "Epoch 00043: val_loss did not improve from 2.03945\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0752 - model_5_loss: 0.5145 - model_6_loss: 0.5087 - model_7_loss: 0.5081 - model_8_loss: 0.5078 - model_5_acc: 0.8108 - model_6_acc: 0.8127 - model_7_acc: 0.8115 - model_8_acc: 0.8119 - val_loss: 2.0395 - val_model_5_loss: 0.5025 - val_model_6_loss: 0.5015 - val_model_7_loss: 0.4990 - val_model_8_loss: 0.5005 - val_model_5_acc: 0.8185 - val_model_6_acc: 0.8135 - val_model_7_acc: 0.8165 - val_model_8_acc: 0.8109\n",
      "Epoch 44/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0908 - model_5_loss: 0.5192 - model_6_loss: 0.5124 - model_7_loss: 0.5119 - model_8_loss: 0.5113 - model_5_acc: 0.8107 - model_6_acc: 0.8115 - model_7_acc: 0.8109 - model_8_acc: 0.8118\n",
      "Epoch 00044: val_loss improved from 2.03945 to 2.03028, saving model to /data/analyses/featurenet_samir/featurenet_samir.h5\n",
      "115/115 [==============================] - 16s 136ms/step - loss: 2.0880 - model_5_loss: 0.5186 - model_6_loss: 0.5117 - model_7_loss: 0.5112 - model_8_loss: 0.5105 - model_5_acc: 0.8111 - model_6_acc: 0.8119 - model_7_acc: 0.8112 - model_8_acc: 0.8122 - val_loss: 2.0303 - val_model_5_loss: 0.4980 - val_model_6_loss: 0.5019 - val_model_7_loss: 0.4944 - val_model_8_loss: 0.5000 - val_model_5_acc: 0.8131 - val_model_6_acc: 0.8143 - val_model_7_acc: 0.8126 - val_model_8_acc: 0.8146\n",
      "Epoch 45/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0973 - model_5_loss: 0.5198 - model_6_loss: 0.5141 - model_7_loss: 0.5137 - model_8_loss: 0.5138 - model_5_acc: 0.8082 - model_6_acc: 0.8083 - model_7_acc: 0.8085 - model_8_acc: 0.8083\n",
      "Epoch 00045: val_loss did not improve from 2.03028\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0979 - model_5_loss: 0.5200 - model_6_loss: 0.5141 - model_7_loss: 0.5139 - model_8_loss: 0.5139 - model_5_acc: 0.8077 - model_6_acc: 0.8079 - model_7_acc: 0.8081 - model_8_acc: 0.8078 - val_loss: 2.0960 - val_model_5_loss: 0.5183 - val_model_6_loss: 0.5160 - val_model_7_loss: 0.5100 - val_model_8_loss: 0.5158 - val_model_5_acc: 0.8151 - val_model_6_acc: 0.8089 - val_model_7_acc: 0.8053 - val_model_8_acc: 0.8188\n",
      "Epoch 46/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0688 - model_5_loss: 0.5136 - model_6_loss: 0.5058 - model_7_loss: 0.5061 - model_8_loss: 0.5073 - model_5_acc: 0.8120 - model_6_acc: 0.8127 - model_7_acc: 0.8130 - model_8_acc: 0.8124\n",
      "Epoch 00046: val_loss did not improve from 2.03028\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0709 - model_5_loss: 0.5142 - model_6_loss: 0.5063 - model_7_loss: 0.5067 - model_8_loss: 0.5078 - model_5_acc: 0.8115 - model_6_acc: 0.8121 - model_7_acc: 0.8125 - model_8_acc: 0.8119 - val_loss: 2.1151 - val_model_5_loss: 0.5208 - val_model_6_loss: 0.5191 - val_model_7_loss: 0.5221 - val_model_8_loss: 0.5172 - val_model_5_acc: 0.8074 - val_model_6_acc: 0.8079 - val_model_7_acc: 0.8157 - val_model_8_acc: 0.8070\n",
      "Epoch 47/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0886 - model_5_loss: 0.5178 - model_6_loss: 0.5119 - model_7_loss: 0.5117 - model_8_loss: 0.5113 - model_5_acc: 0.8096 - model_6_acc: 0.8115 - model_7_acc: 0.8111 - model_8_acc: 0.8107\n",
      "Epoch 00047: val_loss did not improve from 2.03028\n",
      "115/115 [==============================] - 15s 134ms/step - loss: 2.0890 - model_5_loss: 0.5179 - model_6_loss: 0.5120 - model_7_loss: 0.5117 - model_8_loss: 0.5114 - model_5_acc: 0.8096 - model_6_acc: 0.8115 - model_7_acc: 0.8111 - model_8_acc: 0.8107 - val_loss: 2.0649 - val_model_5_loss: 0.5056 - val_model_6_loss: 0.5084 - val_model_7_loss: 0.5047 - val_model_8_loss: 0.5103 - val_model_5_acc: 0.8110 - val_model_6_acc: 0.8197 - val_model_7_acc: 0.8152 - val_model_8_acc: 0.8128\n",
      "Epoch 48/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0582 - model_5_loss: 0.5114 - model_6_loss: 0.5041 - model_7_loss: 0.5029 - model_8_loss: 0.5038 - model_5_acc: 0.8107 - model_6_acc: 0.8128 - model_7_acc: 0.8122 - model_8_acc: 0.8123\n",
      "Epoch 00048: val_loss did not improve from 2.03028\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0587 - model_5_loss: 0.5115 - model_6_loss: 0.5042 - model_7_loss: 0.5031 - model_8_loss: 0.5040 - model_5_acc: 0.8109 - model_6_acc: 0.8130 - model_7_acc: 0.8124 - model_8_acc: 0.8125 - val_loss: 2.0796 - val_model_5_loss: 0.5186 - val_model_6_loss: 0.5118 - val_model_7_loss: 0.5087 - val_model_8_loss: 0.5045 - val_model_5_acc: 0.8177 - val_model_6_acc: 0.8153 - val_model_7_acc: 0.8158 - val_model_8_acc: 0.8143\n",
      "Epoch 49/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0605 - model_5_loss: 0.5104 - model_6_loss: 0.5049 - model_7_loss: 0.5051 - model_8_loss: 0.5040 - model_5_acc: 0.8125 - model_6_acc: 0.8133 - model_7_acc: 0.8134 - model_8_acc: 0.8137\n",
      "Epoch 00049: val_loss did not improve from 2.03028\n",
      "115/115 [==============================] - 15s 134ms/step - loss: 2.0612 - model_5_loss: 0.5107 - model_6_loss: 0.5051 - model_7_loss: 0.5053 - model_8_loss: 0.5042 - model_5_acc: 0.8124 - model_6_acc: 0.8132 - model_7_acc: 0.8133 - model_8_acc: 0.8136 - val_loss: 2.0517 - val_model_5_loss: 0.5097 - val_model_6_loss: 0.5030 - val_model_7_loss: 0.5004 - val_model_8_loss: 0.5027 - val_model_5_acc: 0.8119 - val_model_6_acc: 0.8142 - val_model_7_acc: 0.8088 - val_model_8_acc: 0.8146\n",
      "Epoch 50/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0690 - model_5_loss: 0.5128 - model_6_loss: 0.5067 - model_7_loss: 0.5070 - model_8_loss: 0.5066 - model_5_acc: 0.8098 - model_6_acc: 0.8115 - model_7_acc: 0.8111 - model_8_acc: 0.8110\n",
      "Epoch 00050: val_loss did not improve from 2.03028\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0670 - model_5_loss: 0.5123 - model_6_loss: 0.5062 - model_7_loss: 0.5065 - model_8_loss: 0.5060 - model_5_acc: 0.8101 - model_6_acc: 0.8118 - model_7_acc: 0.8114 - model_8_acc: 0.8113 - val_loss: 2.0761 - val_model_5_loss: 0.5239 - val_model_6_loss: 0.5048 - val_model_7_loss: 0.5085 - val_model_8_loss: 0.5030 - val_model_5_acc: 0.8139 - val_model_6_acc: 0.8159 - val_model_7_acc: 0.8132 - val_model_8_acc: 0.8156\n",
      "Epoch 51/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0540 - model_5_loss: 0.5100 - model_6_loss: 0.5034 - model_7_loss: 0.5025 - model_8_loss: 0.5022 - model_5_acc: 0.8122 - model_6_acc: 0.8130 - model_7_acc: 0.8134 - model_8_acc: 0.8134\n",
      "Epoch 00051: val_loss did not improve from 2.03028\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0766 - model_5_loss: 0.5156 - model_6_loss: 0.5092 - model_7_loss: 0.5077 - model_8_loss: 0.5082 - model_5_acc: 0.8102 - model_6_acc: 0.8108 - model_7_acc: 0.8113 - model_8_acc: 0.8112 - val_loss: 2.0792 - val_model_5_loss: 0.5155 - val_model_6_loss: 0.5133 - val_model_7_loss: 0.5092 - val_model_8_loss: 0.5053 - val_model_5_acc: 0.8138 - val_model_6_acc: 0.8135 - val_model_7_acc: 0.8093 - val_model_8_acc: 0.8125\n",
      "Epoch 52/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0715 - model_5_loss: 0.5145 - model_6_loss: 0.5072 - model_7_loss: 0.5065 - model_8_loss: 0.5073 - model_5_acc: 0.8094 - model_6_acc: 0.8118 - model_7_acc: 0.8110 - model_8_acc: 0.8110\n",
      "Epoch 00052: val_loss did not improve from 2.03028\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0695 - model_5_loss: 0.5141 - model_6_loss: 0.5068 - model_7_loss: 0.5060 - model_8_loss: 0.5068 - model_5_acc: 0.8097 - model_6_acc: 0.8121 - model_7_acc: 0.8113 - model_8_acc: 0.8113 - val_loss: 2.0401 - val_model_5_loss: 0.5036 - val_model_6_loss: 0.5050 - val_model_7_loss: 0.5034 - val_model_8_loss: 0.4923 - val_model_5_acc: 0.8078 - val_model_6_acc: 0.8090 - val_model_7_acc: 0.8077 - val_model_8_acc: 0.8155\n",
      "Epoch 53/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0679 - model_5_loss: 0.5125 - model_6_loss: 0.5066 - model_7_loss: 0.5065 - model_8_loss: 0.5064 - model_5_acc: 0.8098 - model_6_acc: 0.8110 - model_7_acc: 0.8103 - model_8_acc: 0.8108\n",
      "Epoch 00053: val_loss did not improve from 2.03028\n",
      "115/115 [==============================] - 15s 134ms/step - loss: 2.0662 - model_5_loss: 0.5121 - model_6_loss: 0.5062 - model_7_loss: 0.5061 - model_8_loss: 0.5060 - model_5_acc: 0.8100 - model_6_acc: 0.8113 - model_7_acc: 0.8106 - model_8_acc: 0.8111 - val_loss: 2.0692 - val_model_5_loss: 0.5020 - val_model_6_loss: 0.5137 - val_model_7_loss: 0.5052 - val_model_8_loss: 0.5124 - val_model_5_acc: 0.8152 - val_model_6_acc: 0.8066 - val_model_7_acc: 0.8097 - val_model_8_acc: 0.8081\n",
      "Epoch 54/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0766 - model_5_loss: 0.5151 - model_6_loss: 0.5084 - model_7_loss: 0.5087 - model_8_loss: 0.5085 - model_5_acc: 0.8093 - model_6_acc: 0.8116 - model_7_acc: 0.8110 - model_8_acc: 0.8112\n",
      "Epoch 00054: val_loss did not improve from 2.03028\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0738 - model_5_loss: 0.5145 - model_6_loss: 0.5076 - model_7_loss: 0.5080 - model_8_loss: 0.5077 - model_5_acc: 0.8095 - model_6_acc: 0.8119 - model_7_acc: 0.8113 - model_8_acc: 0.8115 - val_loss: 2.0596 - val_model_5_loss: 0.5089 - val_model_6_loss: 0.5063 - val_model_7_loss: 0.5056 - val_model_8_loss: 0.5030 - val_model_5_acc: 0.8179 - val_model_6_acc: 0.8187 - val_model_7_acc: 0.8197 - val_model_8_acc: 0.8218\n",
      "Epoch 55/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0560 - model_5_loss: 0.5100 - model_6_loss: 0.5027 - model_7_loss: 0.5033 - model_8_loss: 0.5041 - model_5_acc: 0.8119 - model_6_acc: 0.8140 - model_7_acc: 0.8135 - model_8_acc: 0.8135\n",
      "Epoch 00055: val_loss did not improve from 2.03028\n",
      "115/115 [==============================] - 16s 135ms/step - loss: 2.0589 - model_5_loss: 0.5107 - model_6_loss: 0.5034 - model_7_loss: 0.5040 - model_8_loss: 0.5048 - model_5_acc: 0.8116 - model_6_acc: 0.8136 - model_7_acc: 0.8131 - model_8_acc: 0.8132 - val_loss: 2.0618 - val_model_5_loss: 0.5057 - val_model_6_loss: 0.5045 - val_model_7_loss: 0.5044 - val_model_8_loss: 0.5113 - val_model_5_acc: 0.8145 - val_model_6_acc: 0.8095 - val_model_7_acc: 0.8109 - val_model_8_acc: 0.8091\n",
      "Epoch 56/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0742 - model_5_loss: 0.5143 - model_6_loss: 0.5082 - model_7_loss: 0.5080 - model_8_loss: 0.5078 - model_5_acc: 0.8104 - model_6_acc: 0.8117 - model_7_acc: 0.8117 - model_8_acc: 0.8122\n",
      "Epoch 00056: val_loss did not improve from 2.03028\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0709 - model_5_loss: 0.5135 - model_6_loss: 0.5073 - model_7_loss: 0.5072 - model_8_loss: 0.5070 - model_5_acc: 0.8108 - model_6_acc: 0.8120 - model_7_acc: 0.8121 - model_8_acc: 0.8126 - val_loss: 2.0517 - val_model_5_loss: 0.5058 - val_model_6_loss: 0.5058 - val_model_7_loss: 0.5037 - val_model_8_loss: 0.5005 - val_model_5_acc: 0.8129 - val_model_6_acc: 0.8061 - val_model_7_acc: 0.8068 - val_model_8_acc: 0.8089\n",
      "Epoch 57/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0474 - model_5_loss: 0.5080 - model_6_loss: 0.5015 - model_7_loss: 0.5004 - model_8_loss: 0.5016 - model_5_acc: 0.8121 - model_6_acc: 0.8150 - model_7_acc: 0.8152 - model_8_acc: 0.8149\n",
      "Epoch 00057: val_loss did not improve from 2.03028\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0468 - model_5_loss: 0.5080 - model_6_loss: 0.5013 - model_7_loss: 0.5002 - model_8_loss: 0.5014 - model_5_acc: 0.8120 - model_6_acc: 0.8150 - model_7_acc: 0.8152 - model_8_acc: 0.8149 - val_loss: 2.0482 - val_model_5_loss: 0.5061 - val_model_6_loss: 0.5039 - val_model_7_loss: 0.4993 - val_model_8_loss: 0.5030 - val_model_5_acc: 0.8164 - val_model_6_acc: 0.8067 - val_model_7_acc: 0.8071 - val_model_8_acc: 0.8075\n",
      "Epoch 58/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0688 - model_5_loss: 0.5131 - model_6_loss: 0.5068 - model_7_loss: 0.5065 - model_8_loss: 0.5065 - model_5_acc: 0.8095 - model_6_acc: 0.8112 - model_7_acc: 0.8117 - model_8_acc: 0.8114\n",
      "Epoch 00058: val_loss did not improve from 2.03028\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0657 - model_5_loss: 0.5123 - model_6_loss: 0.5060 - model_7_loss: 0.5058 - model_8_loss: 0.5057 - model_5_acc: 0.8099 - model_6_acc: 0.8116 - model_7_acc: 0.8121 - model_8_acc: 0.8118 - val_loss: 2.0585 - val_model_5_loss: 0.5052 - val_model_6_loss: 0.5044 - val_model_7_loss: 0.5010 - val_model_8_loss: 0.5121 - val_model_5_acc: 0.8123 - val_model_6_acc: 0.8128 - val_model_7_acc: 0.8071 - val_model_8_acc: 0.8066\n",
      "Epoch 59/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0820 - model_5_loss: 0.5169 - model_6_loss: 0.5102 - model_7_loss: 0.5094 - model_8_loss: 0.5097 - model_5_acc: 0.8090 - model_6_acc: 0.8104 - model_7_acc: 0.8108 - model_8_acc: 0.8107\n",
      "Epoch 00059: val_loss did not improve from 2.03028\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0787 - model_5_loss: 0.5160 - model_6_loss: 0.5094 - model_7_loss: 0.5086 - model_8_loss: 0.5088 - model_5_acc: 0.8093 - model_6_acc: 0.8107 - model_7_acc: 0.8110 - model_8_acc: 0.8109 - val_loss: 2.0327 - val_model_5_loss: 0.5044 - val_model_6_loss: 0.5025 - val_model_7_loss: 0.4953 - val_model_8_loss: 0.4946 - val_model_5_acc: 0.8213 - val_model_6_acc: 0.8198 - val_model_7_acc: 0.8193 - val_model_8_acc: 0.8185\n",
      "Epoch 60/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0383 - model_5_loss: 0.5061 - model_6_loss: 0.4989 - model_7_loss: 0.4987 - model_8_loss: 0.4988 - model_5_acc: 0.8143 - model_6_acc: 0.8156 - model_7_acc: 0.8150 - model_8_acc: 0.8153\n",
      "Epoch 00060: val_loss did not improve from 2.03028\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0378 - model_5_loss: 0.5059 - model_6_loss: 0.4987 - model_7_loss: 0.4986 - model_8_loss: 0.4987 - model_5_acc: 0.8141 - model_6_acc: 0.8154 - model_7_acc: 0.8148 - model_8_acc: 0.8151 - val_loss: 2.0703 - val_model_5_loss: 0.5121 - val_model_6_loss: 0.5069 - val_model_7_loss: 0.5083 - val_model_8_loss: 0.5071 - val_model_5_acc: 0.8159 - val_model_6_acc: 0.8167 - val_model_7_acc: 0.8157 - val_model_8_acc: 0.8219\n",
      "Epoch 61/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0599 - model_5_loss: 0.5106 - model_6_loss: 0.5036 - model_7_loss: 0.5064 - model_8_loss: 0.5034 - model_5_acc: 0.8110 - model_6_acc: 0.8114 - model_7_acc: 0.8102 - model_8_acc: 0.8121\n",
      "Epoch 00061: val_loss did not improve from 2.03028\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0589 - model_5_loss: 0.5102 - model_6_loss: 0.5034 - model_7_loss: 0.5062 - model_8_loss: 0.5032 - model_5_acc: 0.8113 - model_6_acc: 0.8116 - model_7_acc: 0.8105 - model_8_acc: 0.8124 - val_loss: 2.0907 - val_model_5_loss: 0.5091 - val_model_6_loss: 0.5109 - val_model_7_loss: 0.5190 - val_model_8_loss: 0.5158 - val_model_5_acc: 0.8203 - val_model_6_acc: 0.8177 - val_model_7_acc: 0.8220 - val_model_8_acc: 0.8185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0506 - model_5_loss: 0.5080 - model_6_loss: 0.5021 - model_7_loss: 0.5021 - model_8_loss: 0.5025 - model_5_acc: 0.8117 - model_6_acc: 0.8131 - model_7_acc: 0.8135 - model_8_acc: 0.8123\n",
      "Epoch 00062: val_loss did not improve from 2.03028\n",
      "115/115 [==============================] - 15s 134ms/step - loss: 2.0525 - model_5_loss: 0.5085 - model_6_loss: 0.5026 - model_7_loss: 0.5026 - model_8_loss: 0.5029 - model_5_acc: 0.8115 - model_6_acc: 0.8129 - model_7_acc: 0.8133 - model_8_acc: 0.8121 - val_loss: 2.0459 - val_model_5_loss: 0.5090 - val_model_6_loss: 0.4987 - val_model_7_loss: 0.5005 - val_model_8_loss: 0.5018 - val_model_5_acc: 0.8139 - val_model_6_acc: 0.8133 - val_model_7_acc: 0.8135 - val_model_8_acc: 0.8169\n",
      "Epoch 63/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0478 - model_5_loss: 0.5081 - model_6_loss: 0.5015 - model_7_loss: 0.5012 - model_8_loss: 0.5011 - model_5_acc: 0.8123 - model_6_acc: 0.8130 - model_7_acc: 0.8138 - model_8_acc: 0.8129\n",
      "Epoch 00063: val_loss did not improve from 2.03028\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0479 - model_5_loss: 0.5081 - model_6_loss: 0.5015 - model_7_loss: 0.5013 - model_8_loss: 0.5011 - model_5_acc: 0.8123 - model_6_acc: 0.8130 - model_7_acc: 0.8138 - model_8_acc: 0.8129 - val_loss: 2.0571 - val_model_5_loss: 0.5112 - val_model_6_loss: 0.5034 - val_model_7_loss: 0.5041 - val_model_8_loss: 0.5026 - val_model_5_acc: 0.8159 - val_model_6_acc: 0.8126 - val_model_7_acc: 0.8129 - val_model_8_acc: 0.8146\n",
      "Epoch 64/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0631 - model_5_loss: 0.5126 - model_6_loss: 0.5057 - model_7_loss: 0.5046 - model_8_loss: 0.5045 - model_5_acc: 0.8090 - model_6_acc: 0.8109 - model_7_acc: 0.8111 - model_8_acc: 0.8106\n",
      "Epoch 00064: val_loss did not improve from 2.03028\n",
      "115/115 [==============================] - 15s 134ms/step - loss: 2.0593 - model_5_loss: 0.5116 - model_6_loss: 0.5047 - model_7_loss: 0.5036 - model_8_loss: 0.5036 - model_5_acc: 0.8094 - model_6_acc: 0.8113 - model_7_acc: 0.8115 - model_8_acc: 0.8110 - val_loss: 2.0490 - val_model_5_loss: 0.5114 - val_model_6_loss: 0.5008 - val_model_7_loss: 0.5044 - val_model_8_loss: 0.4964 - val_model_5_acc: 0.8221 - val_model_6_acc: 0.8205 - val_model_7_acc: 0.8217 - val_model_8_acc: 0.8215\n",
      "Epoch 65/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0614 - model_5_loss: 0.5114 - model_6_loss: 0.5045 - model_7_loss: 0.5048 - model_8_loss: 0.5049 - model_5_acc: 0.8107 - model_6_acc: 0.8124 - model_7_acc: 0.8118 - model_8_acc: 0.8115\n",
      "Epoch 00065: val_loss did not improve from 2.03028\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0603 - model_5_loss: 0.5112 - model_6_loss: 0.5042 - model_7_loss: 0.5045 - model_8_loss: 0.5046 - model_5_acc: 0.8108 - model_6_acc: 0.8125 - model_7_acc: 0.8119 - model_8_acc: 0.8115 - val_loss: 2.0469 - val_model_5_loss: 0.5124 - val_model_6_loss: 0.4990 - val_model_7_loss: 0.5019 - val_model_8_loss: 0.4977 - val_model_5_acc: 0.8186 - val_model_6_acc: 0.8221 - val_model_7_acc: 0.8187 - val_model_8_acc: 0.8209\n",
      "Epoch 66/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0564 - model_5_loss: 0.5106 - model_6_loss: 0.5031 - model_7_loss: 0.5024 - model_8_loss: 0.5043 - model_5_acc: 0.8098 - model_6_acc: 0.8111 - model_7_acc: 0.8128 - model_8_acc: 0.8105\n",
      "Epoch 00066: val_loss did not improve from 2.03028\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0582 - model_5_loss: 0.5109 - model_6_loss: 0.5036 - model_7_loss: 0.5029 - model_8_loss: 0.5049 - model_5_acc: 0.8096 - model_6_acc: 0.8108 - model_7_acc: 0.8125 - model_8_acc: 0.8102 - val_loss: 2.0459 - val_model_5_loss: 0.5084 - val_model_6_loss: 0.5018 - val_model_7_loss: 0.4995 - val_model_8_loss: 0.5003 - val_model_5_acc: 0.8157 - val_model_6_acc: 0.8112 - val_model_7_acc: 0.8169 - val_model_8_acc: 0.8132\n",
      "Epoch 67/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0605 - model_5_loss: 0.5114 - model_6_loss: 0.5050 - model_7_loss: 0.5042 - model_8_loss: 0.5041 - model_5_acc: 0.8090 - model_6_acc: 0.8110 - model_7_acc: 0.8114 - model_8_acc: 0.8108\n",
      "Epoch 00067: val_loss did not improve from 2.03028\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0602 - model_5_loss: 0.5113 - model_6_loss: 0.5049 - model_7_loss: 0.5041 - model_8_loss: 0.5041 - model_5_acc: 0.8090 - model_6_acc: 0.8110 - model_7_acc: 0.8113 - model_8_acc: 0.8107 - val_loss: 2.0580 - val_model_5_loss: 0.5118 - val_model_6_loss: 0.5035 - val_model_7_loss: 0.5004 - val_model_8_loss: 0.5064 - val_model_5_acc: 0.8133 - val_model_6_acc: 0.8146 - val_model_7_acc: 0.8159 - val_model_8_acc: 0.8162\n",
      "Epoch 68/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0351 - model_5_loss: 0.5054 - model_6_loss: 0.4983 - model_7_loss: 0.4976 - model_8_loss: 0.4980 - model_5_acc: 0.8143 - model_6_acc: 0.8147 - model_7_acc: 0.8153 - model_8_acc: 0.8151\n",
      "Epoch 00068: val_loss did not improve from 2.03028\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0340 - model_5_loss: 0.5050 - model_6_loss: 0.4980 - model_7_loss: 0.4973 - model_8_loss: 0.4978 - model_5_acc: 0.8145 - model_6_acc: 0.8150 - model_7_acc: 0.8156 - model_8_acc: 0.8153 - val_loss: 2.1498 - val_model_5_loss: 0.5309 - val_model_6_loss: 0.5346 - val_model_7_loss: 0.5216 - val_model_8_loss: 0.5269 - val_model_5_acc: 0.8092 - val_model_6_acc: 0.8157 - val_model_7_acc: 0.8117 - val_model_8_acc: 0.8102\n",
      "Epoch 69/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0548 - model_5_loss: 0.5102 - model_6_loss: 0.5027 - model_7_loss: 0.5027 - model_8_loss: 0.5034 - model_5_acc: 0.8121 - model_6_acc: 0.8140 - model_7_acc: 0.8138 - model_8_acc: 0.8137\n",
      "Epoch 00069: val_loss did not improve from 2.03028\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0517 - model_5_loss: 0.5094 - model_6_loss: 0.5019 - model_7_loss: 0.5020 - model_8_loss: 0.5026 - model_5_acc: 0.8125 - model_6_acc: 0.8144 - model_7_acc: 0.8142 - model_8_acc: 0.8140 - val_loss: 2.0640 - val_model_5_loss: 0.5175 - val_model_6_loss: 0.5018 - val_model_7_loss: 0.4953 - val_model_8_loss: 0.5135 - val_model_5_acc: 0.8119 - val_model_6_acc: 0.8096 - val_model_7_acc: 0.8156 - val_model_8_acc: 0.8115\n",
      "Epoch 70/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0450 - model_5_loss: 0.5072 - model_6_loss: 0.5010 - model_7_loss: 0.5003 - model_8_loss: 0.5007 - model_5_acc: 0.8126 - model_6_acc: 0.8133 - model_7_acc: 0.8135 - model_8_acc: 0.8136\n",
      "Epoch 00070: val_loss did not improve from 2.03028\n",
      "115/115 [==============================] - 15s 134ms/step - loss: 2.0424 - model_5_loss: 0.5065 - model_6_loss: 0.5003 - model_7_loss: 0.4996 - model_8_loss: 0.5001 - model_5_acc: 0.8131 - model_6_acc: 0.8137 - model_7_acc: 0.8139 - model_8_acc: 0.8141 - val_loss: 2.0749 - val_model_5_loss: 0.5177 - val_model_6_loss: 0.5108 - val_model_7_loss: 0.5051 - val_model_8_loss: 0.5054 - val_model_5_acc: 0.8199 - val_model_6_acc: 0.8157 - val_model_7_acc: 0.8165 - val_model_8_acc: 0.8176\n",
      "Epoch 71/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0517 - model_5_loss: 0.5100 - model_6_loss: 0.5024 - model_7_loss: 0.5019 - model_8_loss: 0.5015 - model_5_acc: 0.8132 - model_6_acc: 0.8144 - model_7_acc: 0.8152 - model_8_acc: 0.8150\n",
      "Epoch 00071: val_loss did not improve from 2.03028\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0489 - model_5_loss: 0.5093 - model_6_loss: 0.5018 - model_7_loss: 0.5012 - model_8_loss: 0.5008 - model_5_acc: 0.8135 - model_6_acc: 0.8146 - model_7_acc: 0.8155 - model_8_acc: 0.8153 - val_loss: 2.1423 - val_model_5_loss: 0.5220 - val_model_6_loss: 0.5256 - val_model_7_loss: 0.5190 - val_model_8_loss: 0.5399 - val_model_5_acc: 0.8190 - val_model_6_acc: 0.8151 - val_model_7_acc: 0.8082 - val_model_8_acc: 0.8088\n",
      "Epoch 72/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0539 - model_5_loss: 0.5097 - model_6_loss: 0.5028 - model_7_loss: 0.5029 - model_8_loss: 0.5026 - model_5_acc: 0.8105 - model_6_acc: 0.8123 - model_7_acc: 0.8115 - model_8_acc: 0.8118\n",
      "Epoch 00072: val_loss did not improve from 2.03028\n",
      "115/115 [==============================] - 15s 134ms/step - loss: 2.0539 - model_5_loss: 0.5097 - model_6_loss: 0.5028 - model_7_loss: 0.5029 - model_8_loss: 0.5026 - model_5_acc: 0.8106 - model_6_acc: 0.8124 - model_7_acc: 0.8115 - model_8_acc: 0.8119 - val_loss: 2.0526 - val_model_5_loss: 0.5111 - val_model_6_loss: 0.5040 - val_model_7_loss: 0.4993 - val_model_8_loss: 0.5024 - val_model_5_acc: 0.8197 - val_model_6_acc: 0.8213 - val_model_7_acc: 0.8162 - val_model_8_acc: 0.8184\n",
      "Epoch 73/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0748 - model_5_loss: 0.5155 - model_6_loss: 0.5079 - model_7_loss: 0.5078 - model_8_loss: 0.5078 - model_5_acc: 0.8079 - model_6_acc: 0.8095 - model_7_acc: 0.8103 - model_8_acc: 0.8104\n",
      "Epoch 00073: val_loss did not improve from 2.03028\n",
      "115/115 [==============================] - 15s 134ms/step - loss: 2.0746 - model_5_loss: 0.5154 - model_6_loss: 0.5079 - model_7_loss: 0.5077 - model_8_loss: 0.5078 - model_5_acc: 0.8081 - model_6_acc: 0.8098 - model_7_acc: 0.8105 - model_8_acc: 0.8106 - val_loss: 2.0872 - val_model_5_loss: 0.5222 - val_model_6_loss: 0.5076 - val_model_7_loss: 0.5047 - val_model_8_loss: 0.5169 - val_model_5_acc: 0.8087 - val_model_6_acc: 0.8118 - val_model_7_acc: 0.8076 - val_model_8_acc: 0.8112\n",
      "Epoch 74/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0426 - model_5_loss: 0.5068 - model_6_loss: 0.5009 - model_7_loss: 0.4991 - model_8_loss: 0.5000 - model_5_acc: 0.8111 - model_6_acc: 0.8120 - model_7_acc: 0.8124 - model_8_acc: 0.8121\n",
      "Epoch 00074: val_loss did not improve from 2.03028\n",
      "115/115 [==============================] - 15s 134ms/step - loss: 2.0408 - model_5_loss: 0.5064 - model_6_loss: 0.5005 - model_7_loss: 0.4987 - model_8_loss: 0.4994 - model_5_acc: 0.8112 - model_6_acc: 0.8123 - model_7_acc: 0.8126 - model_8_acc: 0.8123 - val_loss: 2.0375 - val_model_5_loss: 0.5033 - val_model_6_loss: 0.5020 - val_model_7_loss: 0.5006 - val_model_8_loss: 0.4957 - val_model_5_acc: 0.8233 - val_model_6_acc: 0.8211 - val_model_7_acc: 0.8181 - val_model_8_acc: 0.8183\n",
      "Epoch 75/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0539 - model_5_loss: 0.5088 - model_6_loss: 0.5033 - model_7_loss: 0.5026 - model_8_loss: 0.5035 - model_5_acc: 0.8107 - model_6_acc: 0.8112 - model_7_acc: 0.8113 - model_8_acc: 0.8109\n",
      "Epoch 00075: val_loss did not improve from 2.03028\n",
      "115/115 [==============================] - 16s 135ms/step - loss: 2.0510 - model_5_loss: 0.5080 - model_6_loss: 0.5025 - model_7_loss: 0.5019 - model_8_loss: 0.5028 - model_5_acc: 0.8110 - model_6_acc: 0.8115 - model_7_acc: 0.8116 - model_8_acc: 0.8112 - val_loss: 2.0584 - val_model_5_loss: 0.5065 - val_model_6_loss: 0.5029 - val_model_7_loss: 0.5097 - val_model_8_loss: 0.5034 - val_model_5_acc: 0.8173 - val_model_6_acc: 0.8153 - val_model_7_acc: 0.8096 - val_model_8_acc: 0.8165\n",
      "Epoch 76/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0366 - model_5_loss: 0.5051 - model_6_loss: 0.4990 - model_7_loss: 0.4982 - model_8_loss: 0.4986 - model_5_acc: 0.8140 - model_6_acc: 0.8144 - model_7_acc: 0.8154 - model_8_acc: 0.8153\n",
      "Epoch 00076: val_loss did not improve from 2.03028\n",
      "115/115 [==============================] - 15s 134ms/step - loss: 2.0413 - model_5_loss: 0.5062 - model_6_loss: 0.5002 - model_7_loss: 0.4994 - model_8_loss: 0.4997 - model_5_acc: 0.8135 - model_6_acc: 0.8139 - model_7_acc: 0.8149 - model_8_acc: 0.8149 - val_loss: 2.0516 - val_model_5_loss: 0.5040 - val_model_6_loss: 0.5087 - val_model_7_loss: 0.4987 - val_model_8_loss: 0.5044 - val_model_5_acc: 0.8119 - val_model_6_acc: 0.8100 - val_model_7_acc: 0.8091 - val_model_8_acc: 0.8131\n",
      "Epoch 77/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0395 - model_5_loss: 0.5063 - model_6_loss: 0.4995 - model_7_loss: 0.4988 - model_8_loss: 0.4991 - model_5_acc: 0.8135 - model_6_acc: 0.8145 - model_7_acc: 0.8156 - model_8_acc: 0.8149\n",
      "Epoch 00077: val_loss did not improve from 2.03028\n",
      "115/115 [==============================] - 15s 134ms/step - loss: 2.0382 - model_5_loss: 0.5060 - model_6_loss: 0.4992 - model_7_loss: 0.4985 - model_8_loss: 0.4988 - model_5_acc: 0.8136 - model_6_acc: 0.8147 - model_7_acc: 0.8158 - model_8_acc: 0.8151 - val_loss: 2.0437 - val_model_5_loss: 0.5119 - val_model_6_loss: 0.5014 - val_model_7_loss: 0.4923 - val_model_8_loss: 0.5024 - val_model_5_acc: 0.8162 - val_model_6_acc: 0.8141 - val_model_7_acc: 0.8157 - val_model_8_acc: 0.8164\n",
      "Epoch 78/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0337 - model_5_loss: 0.5047 - model_6_loss: 0.4979 - model_7_loss: 0.4975 - model_8_loss: 0.4979 - model_5_acc: 0.8118 - model_6_acc: 0.8131 - model_7_acc: 0.8139 - model_8_acc: 0.8141\n",
      "Epoch 00078: val_loss did not improve from 2.03028\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0339 - model_5_loss: 0.5048 - model_6_loss: 0.4979 - model_7_loss: 0.4975 - model_8_loss: 0.4979 - model_5_acc: 0.8121 - model_6_acc: 0.8134 - model_7_acc: 0.8142 - model_8_acc: 0.8144 - val_loss: 2.0502 - val_model_5_loss: 0.5107 - val_model_6_loss: 0.5033 - val_model_7_loss: 0.4993 - val_model_8_loss: 0.5011 - val_model_5_acc: 0.8160 - val_model_6_acc: 0.8159 - val_model_7_acc: 0.8124 - val_model_8_acc: 0.8169\n",
      "Epoch 79/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0489 - model_5_loss: 0.5084 - model_6_loss: 0.5018 - model_7_loss: 0.5018 - model_8_loss: 0.5011 - model_5_acc: 0.8135 - model_6_acc: 0.8153 - model_7_acc: 0.8149 - model_8_acc: 0.8148\n",
      "Epoch 00079: val_loss did not improve from 2.03028\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0534 - model_5_loss: 0.5095 - model_6_loss: 0.5028 - model_7_loss: 0.5030 - model_8_loss: 0.5022 - model_5_acc: 0.8133 - model_6_acc: 0.8151 - model_7_acc: 0.8147 - model_8_acc: 0.8146 - val_loss: 2.0474 - val_model_5_loss: 0.5113 - val_model_6_loss: 0.5029 - val_model_7_loss: 0.4975 - val_model_8_loss: 0.5000 - val_model_5_acc: 0.8113 - val_model_6_acc: 0.8166 - val_model_7_acc: 0.8158 - val_model_8_acc: 0.8151\n",
      "Epoch 80/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0424 - model_5_loss: 0.5075 - model_6_loss: 0.5005 - model_7_loss: 0.4989 - model_8_loss: 0.4997 - model_5_acc: 0.8117 - model_6_acc: 0.8131 - model_7_acc: 0.8131 - model_8_acc: 0.8124\n",
      "Epoch 00080: val_loss did not improve from 2.03028\n",
      "115/115 [==============================] - 15s 134ms/step - loss: 2.0385 - model_5_loss: 0.5065 - model_6_loss: 0.4995 - model_7_loss: 0.4980 - model_8_loss: 0.4987 - model_5_acc: 0.8122 - model_6_acc: 0.8136 - model_7_acc: 0.8136 - model_8_acc: 0.8129 - val_loss: 2.0691 - val_model_5_loss: 0.5110 - val_model_6_loss: 0.5119 - val_model_7_loss: 0.5080 - val_model_8_loss: 0.5025 - val_model_5_acc: 0.8199 - val_model_6_acc: 0.8138 - val_model_7_acc: 0.8107 - val_model_8_acc: 0.8125\n",
      "Epoch 81/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0462 - model_5_loss: 0.5080 - model_6_loss: 0.5011 - model_7_loss: 0.5002 - model_8_loss: 0.5011 - model_5_acc: 0.8111 - model_6_acc: 0.8127 - model_7_acc: 0.8124 - model_8_acc: 0.8121\n",
      "Epoch 00081: val_loss improved from 2.03028 to 2.01135, saving model to /data/analyses/featurenet_samir/featurenet_samir.h5\n",
      "115/115 [==============================] - 16s 136ms/step - loss: 2.0432 - model_5_loss: 0.5073 - model_6_loss: 0.5003 - model_7_loss: 0.4995 - model_8_loss: 0.5003 - model_5_acc: 0.8114 - model_6_acc: 0.8131 - model_7_acc: 0.8128 - model_8_acc: 0.8125 - val_loss: 2.0113 - val_model_5_loss: 0.4992 - val_model_6_loss: 0.4951 - val_model_7_loss: 0.4919 - val_model_8_loss: 0.4894 - val_model_5_acc: 0.8183 - val_model_6_acc: 0.8180 - val_model_7_acc: 0.8146 - val_model_8_acc: 0.8147\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/115 [============================>.] - ETA: 0s - loss: 2.0209 - model_5_loss: 0.5016 - model_6_loss: 0.4954 - model_7_loss: 0.4940 - model_8_loss: 0.4941 - model_5_acc: 0.8120 - model_6_acc: 0.8143 - model_7_acc: 0.8145 - model_8_acc: 0.8140\n",
      "Epoch 00082: val_loss did not improve from 2.01135\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0186 - model_5_loss: 0.5010 - model_6_loss: 0.4949 - model_7_loss: 0.4934 - model_8_loss: 0.4935 - model_5_acc: 0.8122 - model_6_acc: 0.8146 - model_7_acc: 0.8147 - model_8_acc: 0.8143 - val_loss: 2.0114 - val_model_5_loss: 0.5008 - val_model_6_loss: 0.4936 - val_model_7_loss: 0.4905 - val_model_8_loss: 0.4907 - val_model_5_acc: 0.8162 - val_model_6_acc: 0.8121 - val_model_7_acc: 0.8128 - val_model_8_acc: 0.8136\n",
      "Epoch 83/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0474 - model_5_loss: 0.5077 - model_6_loss: 0.5016 - model_7_loss: 0.5014 - model_8_loss: 0.5009 - model_5_acc: 0.8099 - model_6_acc: 0.8109 - model_7_acc: 0.8117 - model_8_acc: 0.8114\n",
      "Epoch 00083: val_loss did not improve from 2.01135\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0442 - model_5_loss: 0.5069 - model_6_loss: 0.5008 - model_7_loss: 0.5006 - model_8_loss: 0.5001 - model_5_acc: 0.8102 - model_6_acc: 0.8113 - model_7_acc: 0.8121 - model_8_acc: 0.8118 - val_loss: 2.0311 - val_model_5_loss: 0.5060 - val_model_6_loss: 0.4991 - val_model_7_loss: 0.4959 - val_model_8_loss: 0.4943 - val_model_5_acc: 0.8181 - val_model_6_acc: 0.8217 - val_model_7_acc: 0.8138 - val_model_8_acc: 0.8203\n",
      "Epoch 84/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0447 - model_5_loss: 0.5083 - model_6_loss: 0.5008 - model_7_loss: 0.4997 - model_8_loss: 0.5001 - model_5_acc: 0.8106 - model_6_acc: 0.8123 - model_7_acc: 0.8125 - model_8_acc: 0.8124\n",
      "Epoch 00084: val_loss did not improve from 2.01135\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0426 - model_5_loss: 0.5077 - model_6_loss: 0.5003 - model_7_loss: 0.4992 - model_8_loss: 0.4996 - model_5_acc: 0.8109 - model_6_acc: 0.8126 - model_7_acc: 0.8128 - model_8_acc: 0.8127 - val_loss: 2.0446 - val_model_5_loss: 0.5092 - val_model_6_loss: 0.4977 - val_model_7_loss: 0.5004 - val_model_8_loss: 0.5014 - val_model_5_acc: 0.8133 - val_model_6_acc: 0.8186 - val_model_7_acc: 0.8185 - val_model_8_acc: 0.8171\n",
      "Epoch 85/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0164 - model_5_loss: 0.5016 - model_6_loss: 0.4930 - model_7_loss: 0.4928 - model_8_loss: 0.4931 - model_5_acc: 0.8151 - model_6_acc: 0.8164 - model_7_acc: 0.8163 - model_8_acc: 0.8164\n",
      "Epoch 00085: val_loss did not improve from 2.01135\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0161 - model_5_loss: 0.5015 - model_6_loss: 0.4930 - model_7_loss: 0.4928 - model_8_loss: 0.4930 - model_5_acc: 0.8152 - model_6_acc: 0.8164 - model_7_acc: 0.8163 - model_8_acc: 0.8164 - val_loss: 2.0406 - val_model_5_loss: 0.5094 - val_model_6_loss: 0.5023 - val_model_7_loss: 0.4980 - val_model_8_loss: 0.4951 - val_model_5_acc: 0.8102 - val_model_6_acc: 0.8141 - val_model_7_acc: 0.8114 - val_model_8_acc: 0.8155\n",
      "Epoch 86/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0226 - model_5_loss: 0.5031 - model_6_loss: 0.4950 - model_7_loss: 0.4945 - model_8_loss: 0.4943 - model_5_acc: 0.8127 - model_6_acc: 0.8130 - model_7_acc: 0.8138 - model_8_acc: 0.8134\n",
      "Epoch 00086: val_loss did not improve from 2.01135\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0190 - model_5_loss: 0.5022 - model_6_loss: 0.4941 - model_7_loss: 0.4936 - model_8_loss: 0.4934 - model_5_acc: 0.8130 - model_6_acc: 0.8134 - model_7_acc: 0.8141 - model_8_acc: 0.8137 - val_loss: 2.0263 - val_model_5_loss: 0.5042 - val_model_6_loss: 0.4959 - val_model_7_loss: 0.4989 - val_model_8_loss: 0.4916 - val_model_5_acc: 0.8143 - val_model_6_acc: 0.8144 - val_model_7_acc: 0.8149 - val_model_8_acc: 0.8151\n",
      "Epoch 87/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0300 - model_5_loss: 0.5043 - model_6_loss: 0.4974 - model_7_loss: 0.4961 - model_8_loss: 0.4965 - model_5_acc: 0.8111 - model_6_acc: 0.8130 - model_7_acc: 0.8129 - model_8_acc: 0.8120\n",
      "Epoch 00087: val_loss did not improve from 2.01135\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0304 - model_5_loss: 0.5044 - model_6_loss: 0.4974 - model_7_loss: 0.4963 - model_8_loss: 0.4966 - model_5_acc: 0.8113 - model_6_acc: 0.8132 - model_7_acc: 0.8131 - model_8_acc: 0.8122 - val_loss: 2.0436 - val_model_5_loss: 0.5061 - val_model_6_loss: 0.5002 - val_model_7_loss: 0.5034 - val_model_8_loss: 0.4982 - val_model_5_acc: 0.8158 - val_model_6_acc: 0.8187 - val_model_7_acc: 0.8175 - val_model_8_acc: 0.8181\n",
      "Epoch 88/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0455 - model_5_loss: 0.5080 - model_6_loss: 0.5008 - model_7_loss: 0.5007 - model_8_loss: 0.5002 - model_5_acc: 0.8110 - model_6_acc: 0.8128 - model_7_acc: 0.8127 - model_8_acc: 0.8126\n",
      "Epoch 00088: val_loss did not improve from 2.01135\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0418 - model_5_loss: 0.5071 - model_6_loss: 0.4999 - model_7_loss: 0.4998 - model_8_loss: 0.4993 - model_5_acc: 0.8114 - model_6_acc: 0.8132 - model_7_acc: 0.8131 - model_8_acc: 0.8130 - val_loss: 2.0512 - val_model_5_loss: 0.5022 - val_model_6_loss: 0.5073 - val_model_7_loss: 0.5036 - val_model_8_loss: 0.5023 - val_model_5_acc: 0.8142 - val_model_6_acc: 0.8194 - val_model_7_acc: 0.8116 - val_model_8_acc: 0.8114\n",
      "Epoch 89/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0432 - model_5_loss: 0.5072 - model_6_loss: 0.5006 - model_7_loss: 0.4997 - model_8_loss: 0.5000 - model_5_acc: 0.8097 - model_6_acc: 0.8108 - model_7_acc: 0.8104 - model_8_acc: 0.8107\n",
      "Epoch 00089: val_loss did not improve from 2.01135\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0399 - model_5_loss: 0.5063 - model_6_loss: 0.4997 - model_7_loss: 0.4989 - model_8_loss: 0.4992 - model_5_acc: 0.8102 - model_6_acc: 0.8113 - model_7_acc: 0.8109 - model_8_acc: 0.8112 - val_loss: 2.0310 - val_model_5_loss: 0.5053 - val_model_6_loss: 0.4970 - val_model_7_loss: 0.4976 - val_model_8_loss: 0.4954 - val_model_5_acc: 0.8176 - val_model_6_acc: 0.8161 - val_model_7_acc: 0.8173 - val_model_8_acc: 0.8139\n",
      "Epoch 90/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0415 - model_5_loss: 0.5076 - model_6_loss: 0.4998 - model_7_loss: 0.4985 - model_8_loss: 0.4999 - model_5_acc: 0.8098 - model_6_acc: 0.8112 - model_7_acc: 0.8111 - model_8_acc: 0.8105\n",
      "Epoch 00090: val_loss did not improve from 2.01135\n",
      "115/115 [==============================] - 15s 132ms/step - loss: 2.0373 - model_5_loss: 0.5065 - model_6_loss: 0.4987 - model_7_loss: 0.4975 - model_8_loss: 0.4988 - model_5_acc: 0.8102 - model_6_acc: 0.8117 - model_7_acc: 0.8115 - model_8_acc: 0.8109 - val_loss: 2.0320 - val_model_5_loss: 0.5095 - val_model_6_loss: 0.4962 - val_model_7_loss: 0.4954 - val_model_8_loss: 0.4952 - val_model_5_acc: 0.8169 - val_model_6_acc: 0.8213 - val_model_7_acc: 0.8190 - val_model_8_acc: 0.8186\n",
      "Epoch 91/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0412 - model_5_loss: 0.5076 - model_6_loss: 0.4997 - model_7_loss: 0.4992 - model_8_loss: 0.4990 - model_5_acc: 0.8117 - model_6_acc: 0.8130 - model_7_acc: 0.8131 - model_8_acc: 0.8126\n",
      "Epoch 00091: val_loss did not improve from 2.01135\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0407 - model_5_loss: 0.5075 - model_6_loss: 0.4995 - model_7_loss: 0.4990 - model_8_loss: 0.4989 - model_5_acc: 0.8117 - model_6_acc: 0.8130 - model_7_acc: 0.8131 - model_8_acc: 0.8126 - val_loss: 2.0738 - val_model_5_loss: 0.5088 - val_model_6_loss: 0.5095 - val_model_7_loss: 0.5095 - val_model_8_loss: 0.5103 - val_model_5_acc: 0.8157 - val_model_6_acc: 0.8176 - val_model_7_acc: 0.8196 - val_model_8_acc: 0.8158\n",
      "Epoch 92/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0089 - model_5_loss: 0.4985 - model_6_loss: 0.4923 - model_7_loss: 0.4909 - model_8_loss: 0.4916 - model_5_acc: 0.8141 - model_6_acc: 0.8156 - model_7_acc: 0.8164 - model_8_acc: 0.8157\n",
      "Epoch 00092: val_loss did not improve from 2.01135\n",
      "115/115 [==============================] - 15s 134ms/step - loss: 2.0065 - model_5_loss: 0.4978 - model_6_loss: 0.4917 - model_7_loss: 0.4903 - model_8_loss: 0.4910 - model_5_acc: 0.8144 - model_6_acc: 0.8159 - model_7_acc: 0.8167 - model_8_acc: 0.8160 - val_loss: 2.0397 - val_model_5_loss: 0.5055 - val_model_6_loss: 0.4991 - val_model_7_loss: 0.5015 - val_model_8_loss: 0.4979 - val_model_5_acc: 0.8135 - val_model_6_acc: 0.8157 - val_model_7_acc: 0.8120 - val_model_8_acc: 0.8153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0203 - model_5_loss: 0.5018 - model_6_loss: 0.4947 - model_7_loss: 0.4943 - model_8_loss: 0.4938 - model_5_acc: 0.8139 - model_6_acc: 0.8158 - model_7_acc: 0.8155 - model_8_acc: 0.8154\n",
      "Epoch 00093: val_loss did not improve from 2.01135\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0190 - model_5_loss: 0.5015 - model_6_loss: 0.4943 - model_7_loss: 0.4940 - model_8_loss: 0.4935 - model_5_acc: 0.8143 - model_6_acc: 0.8162 - model_7_acc: 0.8158 - model_8_acc: 0.8157 - val_loss: 2.0156 - val_model_5_loss: 0.5023 - val_model_6_loss: 0.4961 - val_model_7_loss: 0.4920 - val_model_8_loss: 0.4895 - val_model_5_acc: 0.8242 - val_model_6_acc: 0.8195 - val_model_7_acc: 0.8164 - val_model_8_acc: 0.8190\n",
      "Epoch 94/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0297 - model_5_loss: 0.5045 - model_6_loss: 0.4965 - model_7_loss: 0.4962 - model_8_loss: 0.4967 - model_5_acc: 0.8128 - model_6_acc: 0.8146 - model_7_acc: 0.8151 - model_8_acc: 0.8148\n",
      "Epoch 00094: val_loss did not improve from 2.01135\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0289 - model_5_loss: 0.5044 - model_6_loss: 0.4963 - model_7_loss: 0.4960 - model_8_loss: 0.4965 - model_5_acc: 0.8130 - model_6_acc: 0.8148 - model_7_acc: 0.8153 - model_8_acc: 0.8150 - val_loss: 2.0182 - val_model_5_loss: 0.5055 - val_model_6_loss: 0.4955 - val_model_7_loss: 0.4917 - val_model_8_loss: 0.4897 - val_model_5_acc: 0.8176 - val_model_6_acc: 0.8096 - val_model_7_acc: 0.8097 - val_model_8_acc: 0.8128\n",
      "Epoch 95/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0469 - model_5_loss: 0.5086 - model_6_loss: 0.5014 - model_7_loss: 0.5001 - model_8_loss: 0.5012 - model_5_acc: 0.8108 - model_6_acc: 0.8121 - model_7_acc: 0.8131 - model_8_acc: 0.8128\n",
      "Epoch 00095: val_loss did not improve from 2.01135\n",
      "115/115 [==============================] - 15s 134ms/step - loss: 2.0451 - model_5_loss: 0.5081 - model_6_loss: 0.5009 - model_7_loss: 0.4996 - model_8_loss: 0.5008 - model_5_acc: 0.8110 - model_6_acc: 0.8122 - model_7_acc: 0.8133 - model_8_acc: 0.8130 - val_loss: 2.0152 - val_model_5_loss: 0.5035 - val_model_6_loss: 0.4938 - val_model_7_loss: 0.4906 - val_model_8_loss: 0.4916 - val_model_5_acc: 0.8171 - val_model_6_acc: 0.8222 - val_model_7_acc: 0.8215 - val_model_8_acc: 0.8218\n",
      "Epoch 96/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0366 - model_5_loss: 0.5062 - model_6_loss: 0.4982 - model_7_loss: 0.4981 - model_8_loss: 0.4984 - model_5_acc: 0.8123 - model_6_acc: 0.8132 - model_7_acc: 0.8139 - model_8_acc: 0.8140\n",
      "Epoch 00096: val_loss did not improve from 2.01135\n",
      "115/115 [==============================] - 15s 134ms/step - loss: 2.0331 - model_5_loss: 0.5053 - model_6_loss: 0.4973 - model_7_loss: 0.4972 - model_8_loss: 0.4976 - model_5_acc: 0.8127 - model_6_acc: 0.8136 - model_7_acc: 0.8142 - model_8_acc: 0.8143 - val_loss: 2.0212 - val_model_5_loss: 0.5079 - val_model_6_loss: 0.4903 - val_model_7_loss: 0.4917 - val_model_8_loss: 0.4955 - val_model_5_acc: 0.8139 - val_model_6_acc: 0.8141 - val_model_7_acc: 0.8120 - val_model_8_acc: 0.8132\n",
      "Epoch 97/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0432 - model_5_loss: 0.5073 - model_6_loss: 0.5002 - model_7_loss: 0.4997 - model_8_loss: 0.5004 - model_5_acc: 0.8110 - model_6_acc: 0.8129 - model_7_acc: 0.8133 - model_8_acc: 0.8123\n",
      "Epoch 00097: val_loss did not improve from 2.01135\n",
      "115/115 [==============================] - 15s 134ms/step - loss: 2.0456 - model_5_loss: 0.5079 - model_6_loss: 0.5007 - model_7_loss: 0.5002 - model_8_loss: 0.5010 - model_5_acc: 0.8107 - model_6_acc: 0.8126 - model_7_acc: 0.8131 - model_8_acc: 0.8120 - val_loss: 2.0554 - val_model_5_loss: 0.5148 - val_model_6_loss: 0.5021 - val_model_7_loss: 0.5004 - val_model_8_loss: 0.5025 - val_model_5_acc: 0.8087 - val_model_6_acc: 0.8091 - val_model_7_acc: 0.8129 - val_model_8_acc: 0.8123\n",
      "Epoch 98/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0365 - model_5_loss: 0.5058 - model_6_loss: 0.4988 - model_7_loss: 0.4978 - model_8_loss: 0.4984 - model_5_acc: 0.8123 - model_6_acc: 0.8134 - model_7_acc: 0.8138 - model_8_acc: 0.8135\n",
      "Epoch 00098: val_loss did not improve from 2.01135\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0403 - model_5_loss: 0.5067 - model_6_loss: 0.4998 - model_7_loss: 0.4988 - model_8_loss: 0.4994 - model_5_acc: 0.8116 - model_6_acc: 0.8128 - model_7_acc: 0.8131 - model_8_acc: 0.8129 - val_loss: 2.0349 - val_model_5_loss: 0.5026 - val_model_6_loss: 0.5007 - val_model_7_loss: 0.4956 - val_model_8_loss: 0.5003 - val_model_5_acc: 0.8160 - val_model_6_acc: 0.8138 - val_model_7_acc: 0.8160 - val_model_8_acc: 0.8126\n",
      "Epoch 99/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0295 - model_5_loss: 0.5044 - model_6_loss: 0.4966 - model_7_loss: 0.4960 - model_8_loss: 0.4969 - model_5_acc: 0.8118 - model_6_acc: 0.8133 - model_7_acc: 0.8132 - model_8_acc: 0.8130\n",
      "Epoch 00099: val_loss did not improve from 2.01135\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0278 - model_5_loss: 0.5039 - model_6_loss: 0.4961 - model_7_loss: 0.4956 - model_8_loss: 0.4965 - model_5_acc: 0.8120 - model_6_acc: 0.8135 - model_7_acc: 0.8134 - model_8_acc: 0.8132 - val_loss: 2.0173 - val_model_5_loss: 0.5065 - val_model_6_loss: 0.4908 - val_model_7_loss: 0.4910 - val_model_8_loss: 0.4932 - val_model_5_acc: 0.8148 - val_model_6_acc: 0.8145 - val_model_7_acc: 0.8122 - val_model_8_acc: 0.8149\n",
      "Epoch 100/100\n",
      "114/115 [============================>.] - ETA: 0s - loss: 2.0324 - model_5_loss: 0.5045 - model_6_loss: 0.4983 - model_7_loss: 0.4968 - model_8_loss: 0.4971 - model_5_acc: 0.8143 - model_6_acc: 0.8149 - model_7_acc: 0.8148 - model_8_acc: 0.8148\n",
      "Epoch 00100: val_loss did not improve from 2.01135\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 2.0318 - model_5_loss: 0.5043 - model_6_loss: 0.4982 - model_7_loss: 0.4967 - model_8_loss: 0.4970 - model_5_acc: 0.8144 - model_6_acc: 0.8150 - model_7_acc: 0.8149 - model_8_acc: 0.8149 - val_loss: 2.0508 - val_model_5_loss: 0.5167 - val_model_6_loss: 0.5000 - val_model_7_loss: 0.4983 - val_model_8_loss: 0.5000 - val_model_5_acc: 0.8160 - val_model_6_acc: 0.8140 - val_model_7_acc: 0.8121 - val_model_8_acc: 0.8134\n"
     ]
    }
   ],
   "source": [
    "from deepcell.training import train_model_conv\n",
    "\n",
    "conv_model = train_model_conv(\n",
    "    model=conv_model,\n",
    "    dataset=DATA_FILE,  # full path to npz file\n",
    "    model_name=conv_model_name,\n",
    "    test_size=0.1,\n",
    "    seed=1,\n",
    "    transform=transform,\n",
    "    dilation_radius=dilation_radius,\n",
    "    separate_edge_classes=separate_edge_classes,\n",
    "    optimizer=optimizer,\n",
    "    batch_size=batch_size,\n",
    "    n_epoch=n_epoch,\n",
    "    log_dir=LOG_DIR,\n",
    "    model_dir=MODEL_DIR,\n",
    "    lr_sched=lr_sched,\n",
    "    rotation_range=180,\n",
    "    flip=True,\n",
    "    shear=False,\n",
    "    zoom_range=(0.7, 1/0.7))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
