{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook benchmarks the model output from the StarDist pretrained nuclear model\n",
    "import os\n",
    "import errno\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder for this set of experiments\n",
    "experiment_folder = \"stardist/\"\n",
    "MODEL_DIR = os.path.join(\"/data/analyses/\", experiment_folder)\n",
    "NPZ_DIR = \"/data/npz_data/20201018_freeze/\"\n",
    "LOG_DIR = '/data/logs'\n",
    "\n",
    "if not os.path.isdir(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import binary_dilation, square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n"
     ]
    }
   ],
   "source": [
    "print('loading data')\n",
    "split = '1'\n",
    "test_name = \"20201018_multiplex_seed_{}_test_256x256.npz\".format(split)\n",
    "test_dict = np.load(NPZ_DIR + test_name)\n",
    "\n",
    "y_test = test_dict['y']\n",
    "\n",
    "\n",
    "original_labels = np.load(MODEL_DIR + 'seed_{}_labels.npz'.format(split))['y']\n",
    "expanded_labels = np.zeros_like(original_labels)\n",
    "\n",
    "for img in range(30):\n",
    "    current_label = original_labels[img, :, :, 0]\n",
    "    expanded_label = np.zeros((256, 256))\n",
    "    for cell in np.unique(current_label):\n",
    "        if cell != 0:\n",
    "            mask = current_label == cell\n",
    "            expanded_mask = binary_dilation(mask, square(7))\n",
    "            expanded_label[expanded_mask] = cell\n",
    "    expanded_labels[img, :, :, 0] = expanded_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "relabeling\n",
      "calculating accuracy\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 139873\n",
      "Number of predicted cells:\t 110090\n",
      "\n",
      "Correct detections:  60129\tRecall: 42.9883%\n",
      "Incorrect detections: 49961\tPrecision: 54.618%\n",
      "\n",
      "Gained detections: 23980\tPerc Error: 27.5145%\n",
      "Missed detections: 48757\tPerc Error: 55.9435%\n",
      "Merges: 6031\t\tPerc Error: 6.9199%\n",
      "Splits: 3304\t\tPerc Error: 3.791%\n",
      "Catastrophes: 5082\t\tPerc Error: 5.8311%\n",
      "\n",
      "Gained detections from splits: 4160\n",
      "Missed detections from merges: 7551\n",
      "True detections involved in catastrophes: 2342\n",
      "Predicted detections involved in catastrophes: 2234 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.7015 \n",
      "\n",
      "uid is breast\n",
      "uid is gi\n",
      "uid is immune\n",
      "uid is lung\n",
      "uid is pancreas\n",
      "uid is skin\n",
      "uid is codex\n",
      "uid is cycif\n",
      "uid is imc\n",
      "uid is mibi\n",
      "uid is mxif\n",
      "uid is vectra\n",
      "uid is all\n",
      "0.7229020495056567\n",
      "loading data\n",
      "relabeling\n",
      "calculating accuracy\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 146194\n",
      "Number of predicted cells:\t 115266\n",
      "\n",
      "Correct detections:  62859\tRecall: 42.997%\n",
      "Incorrect detections: 52407\tPrecision: 54.5339%\n",
      "\n",
      "Gained detections: 24734\tPerc Error: 27.424%\n",
      "Missed detections: 50154\tPerc Error: 55.6087%\n",
      "Merges: 6310\t\tPerc Error: 6.9963%\n",
      "Splits: 3485\t\tPerc Error: 3.864%\n",
      "Catastrophes: 5508\t\tPerc Error: 6.107%\n",
      "\n",
      "Gained detections from splits: 4306\n",
      "Missed detections from merges: 8027\n",
      "True detections involved in catastrophes: 2378\n",
      "Predicted detections involved in catastrophes: 2285 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.7077 \n",
      "\n",
      "uid is breast\n",
      "uid is gi\n",
      "uid is immune\n",
      "uid is lung\n",
      "uid is pancreas\n",
      "uid is skin\n",
      "uid is codex\n",
      "uid is cycif\n",
      "uid is imc\n",
      "uid is mibi\n",
      "uid is mxif\n",
      "uid is vectra\n",
      "uid is all\n",
      "0.7219905680374462\n",
      "loading data\n",
      "relabeling\n",
      "calculating accuracy\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 139149\n",
      "Number of predicted cells:\t 108607\n",
      "\n",
      "Correct detections:  59931\tRecall: 43.0697%\n",
      "Incorrect detections: 48676\tPrecision: 55.1815%\n",
      "\n",
      "Gained detections: 23310\tPerc Error: 27.1514%\n",
      "Missed detections: 48383\tPerc Error: 56.3563%\n",
      "Merges: 6011\t\tPerc Error: 7.0016%\n",
      "Splits: 3208\t\tPerc Error: 3.7367%\n",
      "Catastrophes: 4940\t\tPerc Error: 5.7541%\n",
      "\n",
      "Gained detections from splits: 3958\n",
      "Missed detections from merges: 7819\n",
      "True detections involved in catastrophes: 2345\n",
      "Predicted detections involved in catastrophes: 2261 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.7079 \n",
      "\n",
      "uid is breast\n",
      "uid is gi\n",
      "uid is immune\n",
      "uid is lung\n",
      "uid is pancreas\n",
      "uid is skin\n",
      "uid is codex\n",
      "uid is cycif\n",
      "uid is imc\n",
      "uid is mibi\n",
      "uid is mxif\n",
      "uid is vectra\n",
      "uid is all\n",
      "0.7234110304673721\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from deepcell.utils.train_utils import rate_scheduler\n",
    "from deepcell.utils.retinanet_anchor_utils import get_anchor_parameters\n",
    "from deepcell.training import train_model_retinanet\n",
    "from deepcell import model_zoo\n",
    "from deepcell_toolbox.multiplex_utils import multiplex_preprocess\n",
    "from timeit import default_timer\n",
    "from skimage.measure import label\n",
    "from deepcell_toolbox.deep_watershed import deep_watershed_mibi\n",
    "\n",
    "\n",
    "\n",
    "def calc_jaccard_index_object(metric_predictions, true_labels, pred_labels):\n",
    "    jacc_list = []\n",
    "    for i in range(true_labels.shape[0]):\n",
    "        y_true = true_labels[i, :, :, 0]\n",
    "        y_pred = pred_labels[i, :, :, 0]\n",
    "        true_ids = metric_predictions[i][0]['correct']['y_true']\n",
    "        pred_ids = metric_predictions[i][0]['correct']['y_pred']\n",
    "\n",
    "        current_accum = []\n",
    "\n",
    "        for id in range(len(true_ids)):\n",
    "            true_mask = y_true == true_ids[id]\n",
    "            pred_mask = y_pred == pred_ids[id]\n",
    "\n",
    "            current_jacc = (np.sum(np.logical_and(true_mask, pred_mask)) /\n",
    "                np.sum(np.logical_or(true_mask, pred_mask)))\n",
    "            current_accum.append(current_jacc)\n",
    "\n",
    "        jacc_list.append(current_accum)\n",
    "    return jacc_list\n",
    "\n",
    "\n",
    "model_splits = ['1', '2', '3']\n",
    "metrics = {}\n",
    "for split in model_splits:\n",
    "    print('loading data')\n",
    "    test_name = \"20201018_multiplex_seed_{}_test_256x256.npz\".format(split)\n",
    "    test_dict = np.load(NPZ_DIR + test_name)\n",
    "    \n",
    "    y_test = test_dict['y']\n",
    "\n",
    "    \n",
    "    original_labels = np.load(MODEL_DIR + 'seed_{}_labels.npz'.format(split))['y']\n",
    "    expanded_labels = np.zeros_like(original_labels)\n",
    "    \n",
    "    for img in range(original_labels.shape[0]):\n",
    "        current_label = original_labels[img, :, :, 0]\n",
    "        expanded_label = np.zeros((256, 256))\n",
    "        for cell in np.unique(current_label):\n",
    "            if cell != 0:\n",
    "                mask = current_label == cell\n",
    "                expanded_mask = binary_dilation(mask, square(7))\n",
    "                expanded_label[expanded_mask] = cell\n",
    "                \n",
    "    \n",
    "        expanded_labels[img, :, :, 0] = expanded_label\n",
    "    print(\"relabeling\")\n",
    "    for i in range(expanded_labels.shape[0]):\n",
    "        img = expanded_labels[i, :, :, 0]\n",
    "        img = label(img)\n",
    "        expanded_labels[i, :, :, 0] = img\n",
    "    \n",
    "    for i in range(y_test.shape[0]):\n",
    "        img = y_test[i, :, :, 0]\n",
    "        img = label(img)\n",
    "        y_test[i, :, :, 0] = img\n",
    "    \n",
    "    # calculating accuracy\n",
    "    print(\"calculating accuracy\")\n",
    "    db = DatasetBenchmarker(y_true=y_test, \n",
    "                       y_pred=expanded_labels,\n",
    "                       tissue_list=test_dict['tissue_list'],\n",
    "                       platform_list=test_dict['platform_list'],\n",
    "                       model_name='default_model')\n",
    "    tissue_stats, platform_stats = db.benchmark()\n",
    "    \n",
    "    jacc = calc_jaccard_index_object(db.metrics.predictions, y_test, expanded_labels)\n",
    "    jacc = np.concatenate(jacc)\n",
    "    jacc_mean = np.mean(jacc)\n",
    "    print(jacc_mean)\n",
    "    metrics[split] = {'tissue_stats':tissue_stats, 'platform_stats': platform_stats, 'jacc':jacc_mean}\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(os.path.join('/data/analyses/', 'stardist_metrics_jacc.npz'), **metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2016-2020 The Van Valen Lab at the California Institute of\n",
    "# Technology (Caltech), with support from the Paul Allen Family Foundation,\n",
    "# Google, & National Institutes of Health (NIH) under Grant U24CA224309-01.\n",
    "# All rights reserved.\n",
    "#\n",
    "# Licensed under a modified Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.github.com/vanvalenlab/caliban-toolbox/LICENSE\n",
    "#\n",
    "# The Work provided may be used for non-commercial academic purposes only.\n",
    "# For any other use of the Work, including commercial use, please contact:\n",
    "# vanvalenlab@gmail.com\n",
    "#\n",
    "# Neither the name of Caltech nor the names of its contributors may be used\n",
    "# to endorse or promote products derived from this software without specific\n",
    "# prior written permission.\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "\n",
    "from deepcell_toolbox.metrics import Metrics, stats_pixelbased\n",
    "from scipy.stats import hmean\n",
    "\n",
    "\n",
    "class DatasetBenchmarker(object):\n",
    "    \"\"\"Class to perform benchmarking across different tissue and platform types\n",
    "\n",
    "    Args:\n",
    "        y_true: true labels\n",
    "        y_pred: predicted labels\n",
    "        tissue_list: list of tissue names for each image\n",
    "        platform_list: list of platform names for each image\n",
    "        model_name: name of the model used to generate the predictions\n",
    "        metrics_kwargs: arguments to be passed to metrics package\n",
    "\n",
    "    Raises:\n",
    "        ValueError: if y_true and y_pred have different shapes\n",
    "        ValueError: if y_true and y_pred are not 4D\n",
    "        ValueError: if tissue_ids or platform_ids is not same length as labels\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 y_true,\n",
    "                 y_pred,\n",
    "                 tissue_list,\n",
    "                 platform_list,\n",
    "                 model_name,\n",
    "                 metrics_kwargs={}):\n",
    "        if y_true.shape != y_pred.shape:\n",
    "            raise ValueError('Shape mismatch: y_true has shape {}, '\n",
    "                             'y_pred has shape {}. Labels must have the same'\n",
    "                             'shape.'.format(y_true.shape, y_pred.shape))\n",
    "        if len(y_true.shape) != 4:\n",
    "            raise ValueError('Data must be 4D, supplied data is {}'.format(y_true.shape))\n",
    "\n",
    "        self.y_true = y_true\n",
    "        self.y_pred = y_pred\n",
    "\n",
    "        if len({y_true.shape[0], len(tissue_list), len(platform_list)}) != 1:\n",
    "            raise ValueError('Tissue_list and platform_list must have same length as labels')\n",
    "\n",
    "        self.tissue_list = tissue_list\n",
    "        self.platform_list = platform_list\n",
    "        self.model_name = model_name\n",
    "        self.metrics = Metrics(model_name, **metrics_kwargs)\n",
    "\n",
    "    def _benchmark_category(self, category_ids):\n",
    "        \"\"\"Compute benchmark stats over the different categories in supplied list\n",
    "\n",
    "        Args:\n",
    "            category_ids: list specifying which category each image belongs to\n",
    "\n",
    "        Returns:\n",
    "            stats_dict: dictionary of benchmarking results\n",
    "        \"\"\"\n",
    "\n",
    "        unique_ids = np.unique(category_ids)\n",
    "\n",
    "        # create dict to hold stats across each category\n",
    "        stats_dict = {}\n",
    "        for uid in unique_ids:\n",
    "            print(\"uid is {}\".format(uid))\n",
    "            stats_dict[uid] = {}\n",
    "            category_idx = np.isin(category_ids, uid)\n",
    "\n",
    "            # sum metrics across individual images\n",
    "            for key in self.metrics.stats:\n",
    "                stats_dict[uid][key] = self.metrics.stats[key][category_idx].sum()\n",
    "\n",
    "            # compute additional metrics not produced by Metrics class\n",
    "            stats_dict[uid]['recall'] = \\\n",
    "                stats_dict[uid]['correct_detections'] / stats_dict[uid]['n_true']\n",
    "\n",
    "            stats_dict[uid]['precision'] = \\\n",
    "                stats_dict[uid]['correct_detections'] / stats_dict[uid]['n_pred']\n",
    "\n",
    "            stats_dict[uid]['f1'] = \\\n",
    "                hmean([stats_dict[uid]['recall'], stats_dict[uid]['precision']])\n",
    "\n",
    "            pixel_stats = stats_pixelbased(self.y_true[category_idx] != 0,\n",
    "                                           self.y_pred[category_idx] != 0)\n",
    "            stats_dict[uid]['jaccard'] = pixel_stats['jaccard']\n",
    "\n",
    "        return stats_dict\n",
    "\n",
    "    def benchmark(self):\n",
    "        self.metrics.calc_object_stats(self.y_true, self.y_pred)\n",
    "        tissue_stats = self._benchmark_category(category_ids=self.tissue_list)\n",
    "        platform_stats = self._benchmark_category(category_ids=self.platform_list)\n",
    "        all_stats = self._benchmark_category(category_ids=['all'] * len(self.tissue_list))\n",
    "        tissue_stats['all'] = all_stats['all']\n",
    "        platform_stats['all'] = all_stats['all']\n",
    "\n",
    "        return tissue_stats, platform_stats\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
