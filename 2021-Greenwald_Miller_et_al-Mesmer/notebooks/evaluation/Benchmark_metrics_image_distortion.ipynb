{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is to benchmark the model output following image distortions outlined in Extended Data Figure 3j,k,l\n",
    "import os\n",
    "import errno\n",
    "import numpy as np \n",
    "import deepcell\n",
    "from deepcell_toolbox.multiplex_utils import multiplex_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder for this set of experiments\n",
    "experiment_folder = \"image_distortion\"\n",
    "MODEL_DIR = os.path.join(\"/data/analyses\", experiment_folder)\n",
    "NPZ_DIR = \"/data/npz_data/20201018_freeze/\"\n",
    "LOG_DIR = '/data/logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1202 20:29:35.990097 140476373436224 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "from deepcell.model_zoo.panopticnet import PanopticNet\n",
    "\n",
    "model = PanopticNet(\n",
    "    backbone='resnet50',\n",
    "    input_shape=(256,256, 2),\n",
    "    norm_method=None,\n",
    "    num_semantic_heads=2,\n",
    "    num_semantic_classes=[1, 3], # inner distance, outer distance, fgbg, pixelwise\n",
    "    location=True,  # should always be true\n",
    "    include_top=True,\n",
    "    use_imagenet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyzing split 1\n",
      "smooth for loop\n",
      "smooth factor 0.0\n",
      "creating predictions\n",
      "postprocessing\n",
      "calculating accuracy\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 139873\n",
      "Number of predicted cells:\t 137206\n",
      "\n",
      "Correct detections:  114717\tRecall: 82.0151%\n",
      "Incorrect detections: 22489\tPrecision: 83.6093%\n",
      "\n",
      "Gained detections: 13575\tPerc Error: 39.6362%\n",
      "Missed detections: 14856\tPerc Error: 43.3764%\n",
      "Merges: 3068\t\tPerc Error: 8.9579%\n",
      "Splits: 2015\t\tPerc Error: 5.8834%\n",
      "Catastrophes: 735\t\tPerc Error: 2.146%\n",
      "\n",
      "Gained detections from splits: 2167\n",
      "Missed detections from merges: 3424\n",
      "True detections involved in catastrophes: 925\n",
      "Predicted detections involved in catastrophes: 864 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.8668 \n",
      "\n",
      "uid is breast\n",
      "uid is gi\n",
      "uid is immune\n",
      "uid is lung\n",
      "uid is pancreas\n",
      "uid is skin\n",
      "uid is codex\n",
      "uid is cycif\n",
      "uid is imc\n",
      "uid is mibi\n",
      "uid is mxif\n",
      "uid is vectra\n",
      "uid is all\n",
      "smooth factor 0.5\n",
      "creating predictions\n",
      "postprocessing\n",
      "calculating accuracy\n"
     ]
    }
   ],
   "source": [
    "from deepcell_toolbox.deep_watershed import deep_watershed_mibi\n",
    "import scipy.ndimage as nd\n",
    "metrics = {}\n",
    "for model_split in ['1', '2', '3']:\n",
    "    print('analyzing split {}'.format(model_split))\n",
    "    weights = '/data/analyses/size_benchmarking/20201018_multiplex_seed_{}__subset_2665.h5'.format(model_split)\n",
    "    model.load_weights(weights)\n",
    "    \n",
    "    test_dict = np.load(NPZ_DIR + \"20201018_multiplex_seed_{}_test_256x256.npz\".format(model_split))\n",
    "    X_test, y_test = test_dict['X'], test_dict['y']\n",
    "    tissue_list, platform_list = test_dict['tissue_list'], test_dict['platform_list']        \n",
    "    current_dict = {}\n",
    "    print(\"smooth for loop\")\n",
    "    for smooth_factor in np.arange(0, 5.5, 0.5):\n",
    "        print('smooth factor {}'.format(smooth_factor))\n",
    "        X_test_smooth = np.zeros_like(X_test)\n",
    "        for img in range(X_test.shape[0]):\n",
    "            for channel in [0, 1]:\n",
    "                X_test_smooth[img, :, :, channel] = nd.gaussian_filter(X_test[img, :, :, channel].astype('float32'), \n",
    "                                                                       smooth_factor)    \n",
    "\n",
    "        X_test_processed = multiplex_preprocess(X_test_smooth)\n",
    "\n",
    "        print(\"creating predictions\")\n",
    "        inner_distance, pixelwise = model.predict(X_test_processed)\n",
    "\n",
    "        print('postprocessing')\n",
    "        labeled_images = deep_watershed_mibi({'inner-distance': inner_distance[:, :, :, :],\n",
    "                                         'pixelwise-interior': pixelwise[:, :, :, 1:2]}, \n",
    "                                         maxima_threshold=0.1, maxima_model_smooth=0,\n",
    "                                        interior_threshold=0.25, interior_model_smooth=2,\n",
    "                                        radius=3,\n",
    "                                        small_objects_threshold=10,\n",
    "                                         fill_holes_threshold=10)\n",
    "        print(\"calculating accuracy\")\n",
    "        db = DatasetBenchmarker(y_true=y_test, \n",
    "                           y_pred=labeled_images,\n",
    "                           tissue_list=tissue_list,\n",
    "                           platform_list=platform_list,\n",
    "                           model_name='default_model')\n",
    "        tissue_stats, platform_stats = db.benchmark()\n",
    "        current_dict[str(smooth_factor)] = tissue_stats\n",
    "    metrics[model_split] = current_dict\n",
    "np.savez_compressed(os.path.join(MODEL_DIR, 'blurring_metrics_triplicate.npz'), **metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.802484169508037"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics['3']['1.0']['all']['f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(os.path.join(MODEL_DIR, 'blurring_metrics_triplicate.npz'), **metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyzing split 1\n",
      "downsample for loop\n",
      "downsample size 25\n",
      "creating predictions\n",
      "postprocessing\n",
      "calculating accuracy\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 139873\n",
      "Number of predicted cells:\t 53449\n",
      "\n",
      "Correct detections:  16205\tRecall: 11.5855%\n",
      "Incorrect detections: 37244\tPrecision: 30.3186%\n",
      "\n",
      "Gained detections: 9581\tPerc Error: 13.6515%\n",
      "Missed detections: 34259\tPerc Error: 48.8138%\n",
      "Merges: 25124\t\tPerc Error: 35.7978%\n",
      "Splits: 27\t\tPerc Error: 0.0385%\n",
      "Catastrophes: 1192\t\tPerc Error: 1.6984%\n",
      "\n",
      "Gained detections from splits: 27\n",
      "Missed detections from merges: 57607\n",
      "True detections involved in catastrophes: 3507\n",
      "Predicted detections involved in catastrophes: 1386 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.7036 \n",
      "\n",
      "uid is breast\n",
      "uid is gi\n",
      "uid is immune\n",
      "uid is lung\n",
      "uid is pancreas\n",
      "uid is skin\n",
      "uid is codex\n",
      "uid is cycif\n",
      "uid is imc\n",
      "uid is mibi\n",
      "uid is mxif\n",
      "uid is vectra\n",
      "uid is all\n",
      "downsample size 51\n",
      "creating predictions\n",
      "postprocessing\n",
      "calculating accuracy\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 139873\n",
      "Number of predicted cells:\t 97663\n",
      "\n",
      "Correct detections:  65612\tRecall: 46.9083%\n",
      "Incorrect detections: 32051\tPrecision: 67.182%\n",
      "\n",
      "Gained detections: 13458\tPerc Error: 21.7096%\n",
      "Missed detections: 31207\tPerc Error: 50.3412%\n",
      "Merges: 16164\t\tPerc Error: 26.0748%\n",
      "Splits: 225\t\tPerc Error: 0.363%\n",
      "Catastrophes: 937\t\tPerc Error: 1.5115%\n",
      "\n",
      "Gained detections from splits: 228\n",
      "Missed detections from merges: 23424\n",
      "True detections involved in catastrophes: 1624\n",
      "Predicted detections involved in catastrophes: 1028 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.78 \n",
      "\n",
      "uid is breast\n",
      "uid is gi\n",
      "uid is immune\n",
      "uid is lung\n",
      "uid is pancreas\n",
      "uid is skin\n",
      "uid is codex\n",
      "uid is cycif\n",
      "uid is imc\n",
      "uid is mibi\n",
      "uid is mxif\n",
      "uid is vectra\n",
      "uid is all\n",
      "downsample size 76\n",
      "creating predictions\n",
      "postprocessing\n",
      "calculating accuracy\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 139873\n",
      "Number of predicted cells:\t 116574\n",
      "\n",
      "Correct detections:  91214\tRecall: 65.212%\n",
      "Incorrect detections: 25360\tPrecision: 78.2456%\n",
      "\n",
      "Gained detections: 13013\tPerc Error: 26.5566%\n",
      "Missed detections: 25434\tPerc Error: 51.9051%\n",
      "Merges: 8952\t\tPerc Error: 18.269%\n",
      "Splits: 781\t\tPerc Error: 1.5938%\n",
      "Catastrophes: 821\t\tPerc Error: 1.6755%\n",
      "\n",
      "Gained detections from splits: 842\n",
      "Missed detections from merges: 11175\n",
      "True detections involved in catastrophes: 1136\n",
      "Predicted detections involved in catastrophes: 883 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.8151 \n",
      "\n",
      "uid is breast\n",
      "uid is gi\n",
      "uid is immune\n",
      "uid is lung\n",
      "uid is pancreas\n",
      "uid is skin\n",
      "uid is codex\n",
      "uid is cycif\n",
      "uid is imc\n",
      "uid is mibi\n",
      "uid is mxif\n",
      "uid is vectra\n",
      "uid is all\n",
      "downsample size 102\n",
      "creating predictions\n",
      "postprocessing\n",
      "calculating accuracy\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 139873\n",
      "Number of predicted cells:\t 125970\n",
      "\n",
      "Correct detections:  103125\tRecall: 73.7276%\n",
      "Incorrect detections: 22845\tPrecision: 81.8647%\n",
      "\n",
      "Gained detections: 12677\tPerc Error: 30.5942%\n",
      "Missed detections: 20957\tPerc Error: 50.5768%\n",
      "Merges: 5698\t\tPerc Error: 13.7513%\n",
      "Splits: 1306\t\tPerc Error: 3.1518%\n",
      "Catastrophes: 798\t\tPerc Error: 1.9259%\n",
      "\n",
      "Gained detections from splits: 1429\n",
      "Missed detections from merges: 6710\n",
      "True detections involved in catastrophes: 999\n",
      "Predicted detections involved in catastrophes: 853 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.8354 \n",
      "\n",
      "uid is breast\n",
      "uid is gi\n",
      "uid is immune\n",
      "uid is lung\n",
      "uid is pancreas\n",
      "uid is skin\n",
      "uid is codex\n",
      "uid is cycif\n",
      "uid is imc\n",
      "uid is mibi\n",
      "uid is mxif\n",
      "uid is vectra\n",
      "uid is all\n",
      "downsample size 128\n",
      "creating predictions\n",
      "postprocessing\n",
      "calculating accuracy\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 139873\n",
      "Number of predicted cells:\t 129927\n",
      "\n",
      "Correct detections:  107103\tRecall: 76.5716%\n",
      "Incorrect detections: 22824\tPrecision: 82.4332%\n",
      "\n",
      "Gained detections: 13090\tPerc Error: 33.2867%\n",
      "Missed detections: 19195\tPerc Error: 48.8112%\n",
      "Merges: 4667\t\tPerc Error: 11.8678%\n",
      "Splits: 1602\t\tPerc Error: 4.0737%\n",
      "Catastrophes: 771\t\tPerc Error: 1.9606%\n",
      "\n",
      "Gained detections from splits: 1771\n",
      "Missed detections from merges: 5378\n",
      "True detections involved in catastrophes: 946\n",
      "Predicted detections involved in catastrophes: 838 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.8414 \n",
      "\n",
      "uid is breast\n",
      "uid is gi\n",
      "uid is immune\n",
      "uid is lung\n",
      "uid is pancreas\n",
      "uid is skin\n",
      "uid is codex\n",
      "uid is cycif\n",
      "uid is imc\n",
      "uid is mibi\n",
      "uid is mxif\n",
      "uid is vectra\n",
      "uid is all\n",
      "downsample size 153\n",
      "creating predictions\n",
      "postprocessing\n",
      "calculating accuracy\n"
     ]
    }
   ],
   "source": [
    "from deepcell_toolbox.deep_watershed import deep_watershed_mibi\n",
    "from deepcell_toolbox.utils import resize\n",
    "metrics = {}\n",
    "for model_split in ['1', '2', '3']:\n",
    "    print('analyzing split {}'.format(model_split))\n",
    "    weights = '/data/analyses/size_benchmarking/20201018_multiplex_seed_{}__subset_2665.h5'.format(model_split)\n",
    "    model.load_weights(weights)\n",
    "    \n",
    "    test_dict = np.load(NPZ_DIR + \"20201018_multiplex_seed_{}_test_256x256.npz\".format(model_split))\n",
    "    X_test, y_test = test_dict['X'], test_dict['y']\n",
    "    tissue_list, platform_list = test_dict['tissue_list'], test_dict['platform_list']        \n",
    "    current_dict = {}\n",
    "    print(\"downsample for loop\")\n",
    "    for downsample in np.arange(0.1, 1.1, .1):\n",
    "        pixel_size = int(256 * downsample)\n",
    "        print('downsample size {}'.format(pixel_size))\n",
    "        X_test_downsized = resize(X_test.astype('float32'), (pixel_size, pixel_size))\n",
    "        X_test_resized = resize(X_test_downsized, (256, 256))\n",
    "\n",
    "        X_test_processed = multiplex_preprocess(X_test_resized)\n",
    "\n",
    "        print(\"creating predictions\")\n",
    "        inner_distance, pixelwise = model.predict(X_test_processed)\n",
    "\n",
    "        print('postprocessing')\n",
    "        labeled_images = deep_watershed_mibi({'inner-distance': inner_distance[:, :, :, :],\n",
    "                                         'pixelwise-interior': pixelwise[:, :, :, 1:2]}, \n",
    "                                         maxima_threshold=0.1, maxima_model_smooth=0,\n",
    "                                        interior_threshold=0.25, interior_model_smooth=2,\n",
    "                                        radius=3,\n",
    "                                        small_objects_threshold=10,\n",
    "                                         fill_holes_threshold=10)\n",
    "        print(\"calculating accuracy\")\n",
    "        db = DatasetBenchmarker(y_true=y_test, \n",
    "                           y_pred=labeled_images,\n",
    "                           tissue_list=tissue_list,\n",
    "                           platform_list=platform_list,\n",
    "                           model_name='default_model')\n",
    "        tissue_stats, platform_stats = db.benchmark()\n",
    "        current_dict[str(downsample)] = tissue_stats\n",
    "    metrics[model_split] = current_dict\n",
    "np.savez_compressed(os.path.join(MODEL_DIR, 'resize_metrics_triplicate.npz'), **metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(os.path.join(MODEL_DIR, 'resize_metrics.npz'), **metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyzing split 1\n",
      "smooth for loop\n",
      "noise_amount 0.0\n",
      "creating predictions\n",
      "postprocessing\n",
      "calculating accuracy\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 139873\n",
      "Number of predicted cells:\t 137209\n",
      "\n",
      "Correct detections:  114725\tRecall: 82.0208%\n",
      "Incorrect detections: 22484\tPrecision: 83.6133%\n",
      "\n",
      "Gained detections: 13570\tPerc Error: 39.6366%\n",
      "Missed detections: 14852\tPerc Error: 43.3812%\n",
      "Merges: 3063\t\tPerc Error: 8.9467%\n",
      "Splits: 2013\t\tPerc Error: 5.8798%\n",
      "Catastrophes: 738\t\tPerc Error: 2.1556%\n",
      "\n",
      "Gained detections from splits: 2166\n",
      "Missed detections from merges: 3421\n",
      "True detections involved in catastrophes: 927\n",
      "Predicted detections involved in catastrophes: 867 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.8668 \n",
      "\n",
      "uid is breast\n",
      "uid is gi\n",
      "uid is immune\n",
      "uid is lung\n",
      "uid is pancreas\n",
      "uid is skin\n",
      "uid is codex\n",
      "uid is cycif\n",
      "uid is imc\n",
      "uid is mibi\n",
      "uid is mxif\n",
      "uid is vectra\n",
      "uid is all\n",
      "noise_amount 0.02\n",
      "creating predictions\n",
      "postprocessing\n",
      "calculating accuracy\n"
     ]
    }
   ],
   "source": [
    "from deepcell_toolbox.deep_watershed import deep_watershed_mibi\n",
    "metrics = {}\n",
    "for model_split in ['1', '2', '3']:\n",
    "    print('analyzing split {}'.format(model_split))\n",
    "    weights = '/data/analyses/size_benchmarking/20201018_multiplex_seed_{}__subset_2665.h5'.format(model_split)\n",
    "    model.load_weights(weights)\n",
    "    \n",
    "    test_dict = np.load(NPZ_DIR + \"20201018_multiplex_seed_{}_test_256x256.npz\".format(model_split))\n",
    "    X_test, y_test = test_dict['X'], test_dict['y']\n",
    "    tissue_list, platform_list = test_dict['tissue_list'], test_dict['platform_list']        \n",
    "    current_dict = {}\n",
    "    print(\"smooth for loop\")\n",
    "    for noise_max in np.arange(0, 0.2, .02):\n",
    "        noise = np.random.rand(X_test.shape[0], 256, 256, 2)\n",
    "        noise = noise * noise_max\n",
    "        print('noise_amount {}'.format(noise_max))\n",
    "        X_test_combined = X_test + noise\n",
    "\n",
    "        X_test_processed = multiplex_preprocess(X_test_combined)\n",
    "\n",
    "        print(\"creating predictions\")\n",
    "        inner_distance, pixelwise = model.predict(X_test_processed)\n",
    "\n",
    "        print('postprocessing')\n",
    "        labeled_images = deep_watershed_mibi({'inner-distance': inner_distance[:, :, :, :],\n",
    "                                         'pixelwise-interior': pixelwise[:, :, :, 1:2]}, \n",
    "                                         maxima_threshold=0.1, maxima_model_smooth=0,\n",
    "                                        interior_threshold=0.25, interior_model_smooth=2,\n",
    "                                        radius=3,\n",
    "                                        small_objects_threshold=10,\n",
    "                                         fill_holes_threshold=10)\n",
    "        print(\"calculating accuracy\")\n",
    "        db = DatasetBenchmarker(y_true=y_test, \n",
    "                           y_pred=labeled_images,\n",
    "                           tissue_list=tissue_list,\n",
    "                           platform_list=platform_list,\n",
    "                           model_name='default_model')\n",
    "        tissue_stats, platform_stats = db.benchmark()\n",
    "        current_dict[str(noise_max)] = tissue_stats\n",
    "    metrics[model_split] = current_dict\n",
    "np.savez_compressed(os.path.join(MODEL_DIR, 'noise_metrics_triplicate.npz'), **metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5056913996627319"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics['0.18']['all']['f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(os.path.join(MODEL_DIR, 'noise_metrics.npz'), **metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2016-2020 The Van Valen Lab at the California Institute of\n",
    "# Technology (Caltech), with support from the Paul Allen Family Foundation,\n",
    "# Google, & National Institutes of Health (NIH) under Grant U24CA224309-01.\n",
    "# All rights reserved.\n",
    "#\n",
    "# Licensed under a modified Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.github.com/vanvalenlab/caliban-toolbox/LICENSE\n",
    "#\n",
    "# The Work provided may be used for non-commercial academic purposes only.\n",
    "# For any other use of the Work, including commercial use, please contact:\n",
    "# vanvalenlab@gmail.com\n",
    "#\n",
    "# Neither the name of Caltech nor the names of its contributors may be used\n",
    "# to endorse or promote products derived from this software without specific\n",
    "# prior written permission.\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "\n",
    "from deepcell_toolbox.metrics import Metrics, stats_pixelbased\n",
    "from scipy.stats import hmean\n",
    "\n",
    "\n",
    "class DatasetBenchmarker(object):\n",
    "    \"\"\"Class to perform benchmarking across different tissue and platform types\n",
    "\n",
    "    Args:\n",
    "        y_true: true labels\n",
    "        y_pred: predicted labels\n",
    "        tissue_list: list of tissue names for each image\n",
    "        platform_list: list of platform names for each image\n",
    "        model_name: name of the model used to generate the predictions\n",
    "        metrics_kwargs: arguments to be passed to metrics package\n",
    "\n",
    "    Raises:\n",
    "        ValueError: if y_true and y_pred have different shapes\n",
    "        ValueError: if y_true and y_pred are not 4D\n",
    "        ValueError: if tissue_ids or platform_ids is not same length as labels\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 y_true,\n",
    "                 y_pred,\n",
    "                 tissue_list,\n",
    "                 platform_list,\n",
    "                 model_name,\n",
    "                 metrics_kwargs={}):\n",
    "        if y_true.shape != y_pred.shape:\n",
    "            raise ValueError('Shape mismatch: y_true has shape {}, '\n",
    "                             'y_pred has shape {}. Labels must have the same'\n",
    "                             'shape.'.format(y_true.shape, y_pred.shape))\n",
    "        if len(y_true.shape) != 4:\n",
    "            raise ValueError('Data must be 4D, supplied data is {}'.format(y_true.shape))\n",
    "\n",
    "        self.y_true = y_true\n",
    "        self.y_pred = y_pred\n",
    "\n",
    "        if len({y_true.shape[0], len(tissue_list), len(platform_list)}) != 1:\n",
    "            raise ValueError('Tissue_list and platform_list must have same length as labels')\n",
    "\n",
    "        self.tissue_list = tissue_list\n",
    "        self.platform_list = platform_list\n",
    "        self.model_name = model_name\n",
    "        self.metrics = Metrics(model_name, **metrics_kwargs)\n",
    "\n",
    "    def _benchmark_category(self, category_ids):\n",
    "        \"\"\"Compute benchmark stats over the different categories in supplied list\n",
    "\n",
    "        Args:\n",
    "            category_ids: list specifying which category each image belongs to\n",
    "\n",
    "        Returns:\n",
    "            stats_dict: dictionary of benchmarking results\n",
    "        \"\"\"\n",
    "\n",
    "        unique_ids = np.unique(category_ids)\n",
    "\n",
    "        # create dict to hold stats across each category\n",
    "        stats_dict = {}\n",
    "        for uid in unique_ids:\n",
    "            print(\"uid is {}\".format(uid))\n",
    "            stats_dict[uid] = {}\n",
    "            category_idx = np.isin(category_ids, uid)\n",
    "\n",
    "            # sum metrics across individual images\n",
    "            for key in self.metrics.stats:\n",
    "                stats_dict[uid][key] = self.metrics.stats[key][category_idx].sum()\n",
    "\n",
    "            # compute additional metrics not produced by Metrics class\n",
    "            stats_dict[uid]['recall'] = \\\n",
    "                stats_dict[uid]['correct_detections'] / stats_dict[uid]['n_true']\n",
    "\n",
    "            stats_dict[uid]['precision'] = \\\n",
    "                stats_dict[uid]['correct_detections'] / stats_dict[uid]['n_pred']\n",
    "\n",
    "            stats_dict[uid]['f1'] = \\\n",
    "                hmean([stats_dict[uid]['recall'], stats_dict[uid]['precision']])\n",
    "\n",
    "            pixel_stats = stats_pixelbased(self.y_true[category_idx] != 0,\n",
    "                                           self.y_pred[category_idx] != 0)\n",
    "            stats_dict[uid]['jaccard'] = pixel_stats['jaccard']\n",
    "\n",
    "        return stats_dict\n",
    "\n",
    "    def benchmark(self):\n",
    "        self.metrics.calc_object_stats(self.y_true, self.y_pred)\n",
    "        tissue_stats = self._benchmark_category(category_ids=self.tissue_list)\n",
    "        platform_stats = self._benchmark_category(category_ids=self.platform_list)\n",
    "        all_stats = self._benchmark_category(category_ids=['all'] * len(self.tissue_list))\n",
    "        tissue_stats['all'] = all_stats['all']\n",
    "        platform_stats['all'] = all_stats['all']\n",
    "\n",
    "        return tissue_stats, platform_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.exposure import rescale_intensity\n",
    "from skimage.segmentation import find_boundaries\n",
    "import copy\n",
    "def make_color_overlay(input_data):\n",
    "    \"\"\"Create a color overlay from 2 channel image data\n",
    "    \n",
    "    Args:\n",
    "        input_data: stack of input images\n",
    "    \n",
    "    Returns:\n",
    "        numpy.array: color-adjusted stack of overlays in RGB mode\n",
    "    \"\"\"\n",
    "    RGB_data = np.zeros(input_data.shape[:3] + (3, ), dtype='float32')\n",
    "    \n",
    "    # rescale channels to aid plotting\n",
    "    for img in range(input_data.shape[0]):\n",
    "        for channel in range(input_data.shape[-1]):\n",
    "            # get histogram for non-zero pixels\n",
    "            percentiles = np.percentile(input_data[img, :, :, channel][input_data[img, :, :, channel] > 0],\n",
    "                                            [5, 95])\n",
    "            rescaled_intensity = rescale_intensity(input_data[img, :, :, channel],\n",
    "                                                       in_range=(percentiles[0], percentiles[1]),\n",
    "                                                       out_range='float32')\n",
    "            RGB_data[img, :, :, channel + 1] = rescaled_intensity\n",
    "        \n",
    "    # create a blank array for red channel\n",
    "    return RGB_data\n",
    "\n",
    "def make_outline_overlay(RGB_data, predictions):\n",
    "    boundaries = np.zeros_like(predictions)\n",
    "    overlay_data = copy.copy(RGB_data)\n",
    "    \n",
    "    for img in range(predictions.shape[0]):\n",
    "        boundary = find_boundaries(predictions[img], connectivity=1, mode='inner')\n",
    "        boundaries[img, boundary > 0] = 1\n",
    "\n",
    "    overlay_data[boundaries > 0, :] = 1\n",
    "    \n",
    "    return overlay_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
