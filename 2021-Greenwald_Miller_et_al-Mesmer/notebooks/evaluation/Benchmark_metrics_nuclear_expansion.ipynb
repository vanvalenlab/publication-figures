{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is to benchmark the model output from the nuclear-expansion version of the Mesmer model\n",
    "import os\n",
    "import errno\n",
    "import numpy as np \n",
    "import deepcell\n",
    "from deepcell_toolbox.multiplex_utils import multiplex_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder for this set of experiments\n",
    "experiment_folder = \"nuclear_model\"\n",
    "MODEL_DIR = os.path.join(\"/data/analyses\", experiment_folder)\n",
    "NPZ_DIR = \"/data/npz_data/20201018_freeze/\"\n",
    "LOG_DIR = '/data/logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz_ids = ['1' ,'2', '3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_jaccard_index_object(metric_predictions, true_labels, pred_labels):\n",
    "    jacc_list = []\n",
    "    for i in range(true_labels.shape[0]):\n",
    "        y_true = true_labels[i, :, :, 0]\n",
    "        y_pred = pred_labels[i, :, :, 0]\n",
    "        true_ids = metric_predictions[i][0]['correct']['y_true']\n",
    "        pred_ids = metric_predictions[i][0]['correct']['y_pred']\n",
    "\n",
    "        current_accum = []\n",
    "\n",
    "        for id in range(len(true_ids)):\n",
    "            true_mask = y_true == true_ids[id]\n",
    "            pred_mask = y_pred == pred_ids[id]\n",
    "\n",
    "            current_jacc = (np.sum(np.logical_and(true_mask, pred_mask)) /\n",
    "                np.sum(np.logical_or(true_mask, pred_mask)))\n",
    "            current_accum.append(current_jacc)\n",
    "\n",
    "        jacc_list.append(current_accum)\n",
    "    return jacc_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyzing model 1\n",
      "loading data\n",
      "Loading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1204 22:19:40.962188 140097803634496 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n",
      "creating predictions\n",
      "postprocessing\n",
      "calculating accuracy\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 139873\n",
      "Number of predicted cells:\t 116045\n",
      "\n",
      "Correct detections:  89679\tRecall: 64.1146%\n",
      "Incorrect detections: 26366\tPrecision: 77.2795%\n",
      "\n",
      "Gained detections: 15732\tPerc Error: 27.6553%\n",
      "Missed detections: 33231\tPerc Error: 58.4168%\n",
      "Merges: 5512\t\tPerc Error: 9.6896%\n",
      "Splits: 937\t\tPerc Error: 1.6472%\n",
      "Catastrophes: 1474\t\tPerc Error: 2.5911%\n",
      "\n",
      "Gained detections from splits: 997\n",
      "Missed detections from merges: 6626\n",
      "True detections involved in catastrophes: 1413\n",
      "Predicted detections involved in catastrophes: 1201 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.7355 \n",
      "\n",
      "uid is breast\n",
      "uid is gi\n",
      "uid is immune\n",
      "uid is lung\n",
      "uid is pancreas\n",
      "uid is skin\n",
      "uid is codex\n",
      "uid is cycif\n",
      "uid is imc\n",
      "uid is mibi\n",
      "uid is mxif\n",
      "uid is vectra\n",
      "uid is all\n",
      "0.7834279141353268\n",
      "analyzing model 2\n",
      "loading data\n",
      "Loading model\n",
      "preprocessing\n",
      "creating predictions\n",
      "postprocessing\n",
      "calculating accuracy\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 146194\n",
      "Number of predicted cells:\t 121537\n",
      "\n",
      "Correct detections:  93371\tRecall: 63.8679%\n",
      "Incorrect detections: 28166\tPrecision: 76.8252%\n",
      "\n",
      "Gained detections: 16295\tPerc Error: 27.8081%\n",
      "Missed detections: 33259\tPerc Error: 56.7579%\n",
      "Merges: 6505\t\tPerc Error: 11.1011%\n",
      "Splits: 969\t\tPerc Error: 1.6536%\n",
      "Catastrophes: 1570\t\tPerc Error: 2.6793%\n",
      "\n",
      "Gained detections from splits: 1034\n",
      "Missed detections from merges: 7996\n",
      "True detections involved in catastrophes: 1521\n",
      "Predicted detections involved in catastrophes: 1277 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.7429 \n",
      "\n",
      "uid is breast\n",
      "uid is gi\n",
      "uid is immune\n",
      "uid is lung\n",
      "uid is pancreas\n",
      "uid is skin\n",
      "uid is codex\n",
      "uid is cycif\n",
      "uid is imc\n",
      "uid is mibi\n",
      "uid is mxif\n",
      "uid is vectra\n",
      "uid is all\n",
      "0.7828060458607973\n",
      "analyzing model 3\n",
      "loading data\n",
      "Loading model\n",
      "preprocessing\n",
      "creating predictions\n",
      "postprocessing\n",
      "calculating accuracy\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 139149\n",
      "Number of predicted cells:\t 114663\n",
      "\n",
      "Correct detections:  89382\tRecall: 64.2347%\n",
      "Incorrect detections: 25281\tPrecision: 77.9519%\n",
      "\n",
      "Gained detections: 14696\tPerc Error: 26.8337%\n",
      "Missed detections: 31961\tPerc Error: 58.3581%\n",
      "Merges: 5906\t\tPerc Error: 10.7839%\n",
      "Splits: 745\t\tPerc Error: 1.3603%\n",
      "Catastrophes: 1459\t\tPerc Error: 2.664%\n",
      "\n",
      "Gained detections from splits: 786\n",
      "Missed detections from merges: 7273\n",
      "True detections involved in catastrophes: 1372\n",
      "Predicted detections involved in catastrophes: 1182 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.7459 \n",
      "\n",
      "uid is breast\n",
      "uid is gi\n",
      "uid is immune\n",
      "uid is lung\n",
      "uid is pancreas\n",
      "uid is skin\n",
      "uid is codex\n",
      "uid is cycif\n",
      "uid is imc\n",
      "uid is mibi\n",
      "uid is mxif\n",
      "uid is vectra\n",
      "uid is all\n",
      "0.7828384139238989\n"
     ]
    }
   ],
   "source": [
    "from deepcell.model_zoo.panopticnet import PanopticNet\n",
    "from deepcell_toolbox.deep_watershed import deep_watershed_mibi\n",
    "from skimage.measure import label\n",
    "\n",
    "metrics = dict()\n",
    "for current_id in npz_ids:\n",
    "    print(\"analyzing model {}\".format(current_id))\n",
    "    \n",
    "    print('loading data')\n",
    "    npz_name = \"20201018_multiplex_seed_{}_\".format(current_id)\n",
    "\n",
    "    test_dict = np.load(NPZ_DIR + npz_name + \"test_256x256.npz\")\n",
    "    X_test, y_test = test_dict['X'], test_dict['y']\n",
    "    tissue_list, platform_list = test_dict['tissue_list'], test_dict['platform_list']        \n",
    "    \n",
    "    \n",
    "    print('Loading model')\n",
    "    model_name = npz_name + 'nuclear_.h5'\n",
    "    weights_path = os.path.join(MODEL_DIR, model_name)\n",
    "    \n",
    "    # initialize model\n",
    "    model = PanopticNet(\n",
    "        backbone='resnet50',\n",
    "        input_shape=(256, 256, 2),\n",
    "        norm_method=None,\n",
    "        num_semantic_heads=2,\n",
    "        num_semantic_classes=[1, 3], # inner distance, outer distance, fgbg, pixelwise\n",
    "        location=True,  # should always be true\n",
    "        include_top=True,\n",
    "        use_imagenet=False)\n",
    "    \n",
    "    model.load_weights(weights_path)\n",
    "    \n",
    "    print('preprocessing')\n",
    "    X_test = multiplex_preprocess(X_test)\n",
    "    # X_test = normalize(X_test)\n",
    "    \n",
    "    print(\"creating predictions\")\n",
    "    inner_distance, pixelwise = model.predict(X_test)\n",
    "    \n",
    "    print('postprocessing')\n",
    "    labeled_images = deep_watershed_mibi({'inner-distance': inner_distance,\n",
    "                                     'pixelwise-interior': pixelwise[:, :, :, 1:2]}, \n",
    "                                     maxima_threshold=0.3, maxima_model_smooth=0,\n",
    "                                    interior_threshold=0.3, interior_model_smooth=2,\n",
    "                                    radius=3,\n",
    "                                    small_objects_threshold=10,\n",
    "                                     fill_holes_threshold=10,\n",
    "                                        pixel_expansion=3)\n",
    "    print(\"calculating accuracy\")\n",
    "    \n",
    "    for i in range(labeled_images.shape[0]):\n",
    "        img = labeled_images[i, :, :, 0]\n",
    "        img = label(img)\n",
    "        labeled_images[i, :, :, 0] = img\n",
    "    \n",
    "    for i in range(y_test.shape[0]):\n",
    "        img = y_test[i, :, :, 0]\n",
    "        img = label(img)\n",
    "        y_test[i, :, :, 0] = img\n",
    "    db = DatasetBenchmarker(y_true=y_test, \n",
    "                       y_pred=labeled_images,\n",
    "                       tissue_list=tissue_list,\n",
    "                       platform_list=platform_list,\n",
    "                       model_name='default_model')\n",
    "    tissue_stats, platform_stats = db.benchmark()\n",
    "    jacc = calc_jaccard_index_object(db.metrics.predictions, y_test, labeled_images)\n",
    "    jacc = np.concatenate(jacc)\n",
    "    jacc_mean = np.mean(jacc)\n",
    "    print(jacc_mean)\n",
    "    metrics[current_id] = {'tissue_stats':tissue_stats, 'platform_stats': platform_stats,\n",
    "                          'jacc': jacc_mean}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7828384139238989"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics['3']['jacc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(os.path.join(MODEL_DIR, 'nuclear_metrics_jacc.npz'), **metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2016-2020 The Van Valen Lab at the California Institute of\n",
    "# Technology (Caltech), with support from the Paul Allen Family Foundation,\n",
    "# Google, & National Institutes of Health (NIH) under Grant U24CA224309-01.\n",
    "# All rights reserved.\n",
    "#\n",
    "# Licensed under a modified Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.github.com/vanvalenlab/caliban-toolbox/LICENSE\n",
    "#\n",
    "# The Work provided may be used for non-commercial academic purposes only.\n",
    "# For any other use of the Work, including commercial use, please contact:\n",
    "# vanvalenlab@gmail.com\n",
    "#\n",
    "# Neither the name of Caltech nor the names of its contributors may be used\n",
    "# to endorse or promote products derived from this software without specific\n",
    "# prior written permission.\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "\n",
    "from deepcell_toolbox.metrics import Metrics, stats_pixelbased\n",
    "from scipy.stats import hmean\n",
    "\n",
    "\n",
    "class DatasetBenchmarker(object):\n",
    "    \"\"\"Class to perform benchmarking across different tissue and platform types\n",
    "\n",
    "    Args:\n",
    "        y_true: true labels\n",
    "        y_pred: predicted labels\n",
    "        tissue_list: list of tissue names for each image\n",
    "        platform_list: list of platform names for each image\n",
    "        model_name: name of the model used to generate the predictions\n",
    "        metrics_kwargs: arguments to be passed to metrics package\n",
    "\n",
    "    Raises:\n",
    "        ValueError: if y_true and y_pred have different shapes\n",
    "        ValueError: if y_true and y_pred are not 4D\n",
    "        ValueError: if tissue_ids or platform_ids is not same length as labels\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 y_true,\n",
    "                 y_pred,\n",
    "                 tissue_list,\n",
    "                 platform_list,\n",
    "                 model_name,\n",
    "                 metrics_kwargs={}):\n",
    "        if y_true.shape != y_pred.shape:\n",
    "            raise ValueError('Shape mismatch: y_true has shape {}, '\n",
    "                             'y_pred has shape {}. Labels must have the same'\n",
    "                             'shape.'.format(y_true.shape, y_pred.shape))\n",
    "        if len(y_true.shape) != 4:\n",
    "            raise ValueError('Data must be 4D, supplied data is {}'.format(y_true.shape))\n",
    "\n",
    "        self.y_true = y_true\n",
    "        self.y_pred = y_pred\n",
    "\n",
    "        if len({y_true.shape[0], len(tissue_list), len(platform_list)}) != 1:\n",
    "            raise ValueError('Tissue_list and platform_list must have same length as labels')\n",
    "\n",
    "        self.tissue_list = tissue_list\n",
    "        self.platform_list = platform_list\n",
    "        self.model_name = model_name\n",
    "        self.metrics = Metrics(model_name, **metrics_kwargs)\n",
    "\n",
    "    def _benchmark_category(self, category_ids):\n",
    "        \"\"\"Compute benchmark stats over the different categories in supplied list\n",
    "\n",
    "        Args:\n",
    "            category_ids: list specifying which category each image belongs to\n",
    "\n",
    "        Returns:\n",
    "            stats_dict: dictionary of benchmarking results\n",
    "        \"\"\"\n",
    "\n",
    "        unique_ids = np.unique(category_ids)\n",
    "\n",
    "        # create dict to hold stats across each category\n",
    "        stats_dict = {}\n",
    "        for uid in unique_ids:\n",
    "            print(\"uid is {}\".format(uid))\n",
    "            stats_dict[uid] = {}\n",
    "            category_idx = np.isin(category_ids, uid)\n",
    "\n",
    "            # sum metrics across individual images\n",
    "            for key in self.metrics.stats:\n",
    "                stats_dict[uid][key] = self.metrics.stats[key][category_idx].sum()\n",
    "\n",
    "            # compute additional metrics not produced by Metrics class\n",
    "            stats_dict[uid]['recall'] = \\\n",
    "                stats_dict[uid]['correct_detections'] / stats_dict[uid]['n_true']\n",
    "\n",
    "            stats_dict[uid]['precision'] = \\\n",
    "                stats_dict[uid]['correct_detections'] / stats_dict[uid]['n_pred']\n",
    "\n",
    "            stats_dict[uid]['f1'] = \\\n",
    "                hmean([stats_dict[uid]['recall'], stats_dict[uid]['precision']])\n",
    "\n",
    "            pixel_stats = stats_pixelbased(self.y_true[category_idx] != 0,\n",
    "                                           self.y_pred[category_idx] != 0)\n",
    "            stats_dict[uid]['jaccard'] = pixel_stats['jaccard']\n",
    "\n",
    "        return stats_dict\n",
    "\n",
    "    def benchmark(self):\n",
    "        self.metrics.calc_object_stats(self.y_true, self.y_pred)\n",
    "        tissue_stats = self._benchmark_category(category_ids=self.tissue_list)\n",
    "        platform_stats = self._benchmark_category(category_ids=self.platform_list)\n",
    "        all_stats = self._benchmark_category(category_ids=['all'] * len(self.tissue_list))\n",
    "        tissue_stats['all'] = all_stats['all']\n",
    "        platform_stats['all'] = all_stats['all']\n",
    "\n",
    "        return tissue_stats, platform_stats\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
